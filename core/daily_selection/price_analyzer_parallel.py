"""
ë³‘ë ¬ì²˜ë¦¬ ê°€ê²© ë§¤ë ¥ë„ ë¶„ì„ ì‹œìŠ¤í…œ
- ë©€í‹°ìŠ¤ë ˆë”© ê¸°ë°˜ ì¢…ëª© ë¶„ì„
- ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- ì„±ëŠ¥ í–¥ìƒëœ Phase2 ë¶„ì„
"""

import os
import sys
import time
import logging
import multiprocessing as mp
import concurrent.futures
from typing import Dict, List, Optional, Any
from datetime import datetime
from functools import partial

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# ê¸°ì¡´ PriceAnalyzer í´ë˜ìŠ¤ import
from core.daily_selection.price_analyzer import PriceAnalyzer, PriceAttractiveness
from core.utils.log_utils import get_logger

logger = get_logger(__name__)

class ParallelPriceAnalyzer(PriceAnalyzer):
    """ë³‘ë ¬ì²˜ë¦¬ ê°€ê²© ë§¤ë ¥ë„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, p_config_file: str = "core/config/api_config.py", p_max_workers: int = None):
        """ì´ˆê¸°í™”

        Args:
            p_config_file: ì„¤ì • íŒŒì¼ ê²½ë¡œ
            p_max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜ (Noneì´ë©´ 1, API Rate Limit ì¤€ìˆ˜)

        Note:
            KIS API Rate Limit: ì‹¤ì „ 20ê±´/ì´ˆ, ëª¨ì˜ 5ê±´/ì´ˆ
            Rate Limit ì´ˆê³¼ ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ë³¸ê°’ 1ë¡œ ì„¤ì • (ìˆœì°¨ ì²˜ë¦¬)
        """
        super().__init__(p_config_file)
        # API rate limit ë°©ì§€ë¥¼ ìœ„í•´ ì›Œì»¤ ìˆ˜ ì œí•œ (ê¸°ë³¸ê°’ 1, ìˆœì°¨ ì²˜ë¦¬)
        self._v_max_workers = p_max_workers or 1
        logger.info(f"ë³‘ë ¬ ê°€ê²© ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ - ì›Œì»¤ ìˆ˜: {self._v_max_workers}")
    
    def parallel_analyze_multiple_stocks(self, p_stock_list: List[Dict], p_batch_size: int = 20) -> List[PriceAttractiveness]:
        """ë³‘ë ¬ ë‹¤ì¤‘ ì¢…ëª© ë¶„ì„
        
        Args:
            p_stock_list: ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            p_batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ë³‘ë ¬ ë‹¤ì¤‘ ì¢…ëª© ë¶„ì„ ì‹œì‘: {len(p_stock_list)}ê°œ ì¢…ëª©, ì›Œì»¤: {self._v_max_workers}ê°œ")
            
            _v_results = []
            
            # ThreadPoolExecutor ì‚¬ìš© (I/O ì§‘ì•½ì  ì‘ì—…)
            with concurrent.futures.ThreadPoolExecutor(max_workers=self._v_max_workers) as executor:
                # ê° ì¢…ëª©ì— ëŒ€í•´ Future ìƒì„±
                _v_futures = {
                    executor.submit(self._analyze_single_stock_wrapper, stock_data): i 
                    for i, stock_data in enumerate(p_stock_list)
                }
                
                # ì™„ë£Œëœ ì¢…ëª© ê²°ê³¼ ìˆ˜ì§‘
                for future in concurrent.futures.as_completed(_v_futures):
                    _v_stock_idx = _v_futures[future]
                    
                    try:
                        _v_result = future.result()
                        if _v_result:
                            _v_results.append(_v_result)
                            
                        # ì§„í–‰ ìƒí™© ë¡œê¹…
                        if len(_v_results) % 10 == 0:
                            logger.info(f"ë¶„ì„ ì§„í–‰: {len(_v_results)}/{len(p_stock_list)} ì™„ë£Œ")
                            
                    except Exception as e:
                        _v_stock_code = p_stock_list[_v_stock_idx].get("stock_code", "Unknown")
                        logger.error(f"ì¢…ëª© {_v_stock_code} ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
                        continue
            
            logger.info(f"ë³‘ë ¬ ë‹¤ì¤‘ ì¢…ëª© ë¶„ì„ ì™„ë£Œ: {len(_v_results)}ê°œ ê²°ê³¼")
            return _v_results
            
        except Exception as e:
            logger.error(f"ë³‘ë ¬ ë‹¤ì¤‘ ì¢…ëª© ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
            return []
    
    def batch_analyze_stocks(self, p_stock_list: List[Dict], p_batch_size: int = 50) -> List[PriceAttractiveness]:
        """ë°°ì¹˜ ê¸°ë°˜ ì¢…ëª© ë¶„ì„ (í”„ë¡œì„¸ìŠ¤ í’€ í™œìš©)
        
        Args:
            p_stock_list: ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            p_batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ë°°ì¹˜ ì¢…ëª© ë¶„ì„ ì‹œì‘: {len(p_stock_list)}ê°œ ì¢…ëª©")
            
            # ë°°ì¹˜ ìƒì„±
            _v_batches = [p_stock_list[i:i + p_batch_size] for i in range(0, len(p_stock_list), p_batch_size)]
            logger.info(f"ë°°ì¹˜ ìƒì„± ì™„ë£Œ: {len(_v_batches)}ê°œ ë°°ì¹˜")
            
            _v_all_results = []
            
            # ProcessPoolExecutor ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬
            with concurrent.futures.ProcessPoolExecutor(max_workers=self._v_max_workers) as executor:
                # ê° ë°°ì¹˜ì— ëŒ€í•´ Future ìƒì„±
                _v_batch_function = partial(self._process_analysis_batch_worker, 
                                          weights=self._v_weights)
                
                _v_futures = {
                    executor.submit(_v_batch_function, batch): i 
                    for i, batch in enumerate(_v_batches)
                }
                
                # ì™„ë£Œëœ ë°°ì¹˜ ê²°ê³¼ ìˆ˜ì§‘
                for future in concurrent.futures.as_completed(_v_futures):
                    _v_batch_idx = _v_futures[future]
                    
                    try:
                        _v_batch_results = future.result()
                        _v_all_results.extend(_v_batch_results)
                        
                        logger.info(f"ë°°ì¹˜ {_v_batch_idx + 1} ì™„ë£Œ: {len(_v_batch_results)}ê°œ ë¶„ì„")
                        print(f"ğŸ”„ ë¶„ì„ ë°°ì¹˜ {_v_batch_idx + 1}/{len(_v_batches)} ì™„ë£Œ")
                        
                    except Exception as e:
                        logger.error(f"ë°°ì¹˜ {_v_batch_idx + 1} ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
                        continue
            
            logger.info(f"ë°°ì¹˜ ì¢…ëª© ë¶„ì„ ì™„ë£Œ - ì´ {len(_v_all_results)}ê°œ ê²°ê³¼")
            return _v_all_results
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì¢…ëª© ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
            return []
    
    def _analyze_single_stock_wrapper(self, p_stock_data: Dict) -> Optional[PriceAttractiveness]:
        """ë‹¨ì¼ ì¢…ëª© ë¶„ì„ ë˜í¼ (ìŠ¤ë ˆë“œ ì›Œì»¤ìš©)
        
        Args:
            p_stock_data: ì¢…ëª© ë°ì´í„°
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë˜ëŠ” None
        """
        try:
            return self.analyze_price_attractiveness(p_stock_data)
            
        except Exception as e:
            logger.error(f"ì¢…ëª© ë¶„ì„ ë˜í¼ ì˜¤ë¥˜ ({p_stock_data.get('stock_code', 'Unknown')}): {e}", exc_info=True)
            return None
    
    @staticmethod
    def _process_analysis_batch_worker(p_batch: List[Dict], weights: Dict) -> List[PriceAttractiveness]:
        """ë°°ì¹˜ ë¶„ì„ ì›Œì»¤ í•¨ìˆ˜ (í”„ë¡œì„¸ìŠ¤ í’€ ì›Œì»¤ìš©)
        
        Args:
            p_batch: ë°°ì¹˜ ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            weights: ë¶„ì„ ê°€ì¤‘ì¹˜
            
        Returns:
            ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì—ì„œ ìƒˆë¡œìš´ PriceAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            _v_analyzer = PriceAnalyzer()
            _v_analyzer._v_weights = weights
            
            # ë°°ì¹˜ ë‚´ ì¢…ëª©ë“¤ ìˆœì°¨ ë¶„ì„
            _v_batch_results = []
            for stock_data in p_batch:
                try:
                    _v_result = _v_analyzer.analyze_price_attractiveness(stock_data)
                    if _v_result:
                        _v_batch_results.append(_v_result)
                        
                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ì›Œì»¤ ì¢…ëª© ë¶„ì„ ì˜¤ë¥˜ ({stock_data.get('stock_code', 'Unknown')}): {e}", exc_info=True)
                    continue
            
            return _v_batch_results
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ë¶„ì„ ì›Œì»¤ ì˜¤ë¥˜: {e}", exc_info=True)
            return []
    
    def concurrent_technical_analysis(self, p_stock_data_list: List[Dict]) -> List[Dict]:
        """ë™ì‹œ ê¸°ìˆ ì  ë¶„ì„ (ê¸°ìˆ ì  ì§€í‘œ ë³‘ë ¬ ê³„ì‚°)
        
        Args:
            p_stock_data_list: ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ë™ì‹œ ê¸°ìˆ ì  ë¶„ì„ ì‹œì‘: {len(p_stock_data_list)}ê°œ ì¢…ëª©")
            
            _v_results = []
            
            # ThreadPoolExecutor ì‚¬ìš©í•˜ì—¬ ê¸°ìˆ ì  ë¶„ì„ ë³‘ë ¬í™”
            with concurrent.futures.ThreadPoolExecutor(max_workers=self._v_max_workers * 2) as executor:
                # ê° ì¢…ëª©ì— ëŒ€í•´ Future ìƒì„±
                _v_futures = {
                    executor.submit(self._analyze_technical_indicators, stock_data): stock_data.get("stock_code", "Unknown")
                    for stock_data in p_stock_data_list
                }
                
                # ì™„ë£Œëœ ê²°ê³¼ ìˆ˜ì§‘
                for future in concurrent.futures.as_completed(_v_futures):
                    _v_stock_code = _v_futures[future]
                    
                    try:
                        _v_technical_score, _v_technical_signals = future.result()
                        _v_results.append({
                            "stock_code": _v_stock_code,
                            "technical_score": _v_technical_score,
                            "technical_signals": _v_technical_signals
                        })
                        
                    except Exception as e:
                        logger.error(f"ì¢…ëª© {_v_stock_code} ê¸°ìˆ ì  ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
                        continue
            
            logger.info(f"ë™ì‹œ ê¸°ìˆ ì  ë¶„ì„ ì™„ë£Œ: {len(_v_results)}ê°œ ê²°ê³¼")
            return _v_results
            
        except Exception as e:
            logger.error(f"ë™ì‹œ ê¸°ìˆ ì  ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
            return []
    
    def get_performance_comparison(self, p_stock_list: List[Dict]) -> Dict:
        """ì„±ëŠ¥ ë¹„êµ (ìˆœì°¨ vs ë³‘ë ¬)
        
        Args:
            p_stock_list: í…ŒìŠ¤íŠ¸í•  ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
        """
        try:
            logger.info(f"ì„±ëŠ¥ ë¹„êµ ì‹œì‘: {len(p_stock_list)}ê°œ ì¢…ëª©")
            
            # ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            _v_start_time = time.time()
            _v_sequential_results = super().analyze_multiple_stocks(p_stock_list)
            _v_sequential_time = time.time() - _v_start_time
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            _v_start_time = time.time()
            _v_parallel_results = self.parallel_analyze_multiple_stocks(p_stock_list)
            _v_parallel_time = time.time() - _v_start_time
            
            # ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
            _v_speedup = _v_sequential_time / _v_parallel_time if _v_parallel_time > 0 else 0
            
            _v_comparison = {
                "stock_count": len(p_stock_list),
                "sequential_time": _v_sequential_time,
                "parallel_time": _v_parallel_time,
                "speedup": _v_speedup,
                "sequential_results": len(_v_sequential_results),
                "parallel_results": len(_v_parallel_results),
                "efficiency": _v_speedup / self._v_max_workers if self._v_max_workers > 0 else 0,
                "workers": self._v_max_workers,
                "recommendation": self._get_performance_recommendation(_v_speedup)
            }
            
            logger.info(f"ì„±ëŠ¥ ë¹„êµ ì™„ë£Œ - ì†ë„ í–¥ìƒ: {_v_speedup:.2f}ë°°")
            return _v_comparison
            
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ë¹„êµ ì˜¤ë¥˜: {e}", exc_info=True)
            return {}
    
    def _get_performance_recommendation(self, p_speedup: float) -> str:
        """ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        
        Args:
            p_speedup: ì†ë„ í–¥ìƒ ë°°ìˆ˜
            
        Returns:
            ì¶”ì²œ ì‚¬í•­
        """
        if p_speedup >= 3.0:
            return "ë³‘ë ¬ ì²˜ë¦¬ ë§¤ìš° íš¨ê³¼ì  - ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì‚¬ìš© ê¶Œì¥"
        elif p_speedup >= 2.0:
            return "ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ì  - ì¤‘ê°„ ê·œëª¨ ì´ìƒ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì‚¬ìš© ê¶Œì¥"
        elif p_speedup >= 1.5:
            return "ë³‘ë ¬ ì²˜ë¦¬ ë³´í†µ íš¨ê³¼ - ì†Œê·œëª¨ ë°ì´í„°ëŠ” ìˆœì°¨ ì²˜ë¦¬ ê¶Œì¥"
        else:
            return "ë³‘ë ¬ ì²˜ë¦¬ ì˜¤ë²„í—¤ë“œ í¼ - ìˆœì°¨ ì²˜ë¦¬ ê¶Œì¥"
    
    def get_optimization_metrics(self) -> Dict:
        """ìµœì í™” ë©”íŠ¸ë¦­ ì¡°íšŒ
        
        Returns:
            ìµœì í™” ë©”íŠ¸ë¦­ ì •ë³´
        """
        return {
            "max_workers": self._v_max_workers,
            "cpu_count": mp.cpu_count(),
            "recommended_batch_size": self._v_max_workers * 5,
            "memory_estimation": {
                "per_stock_mb": 0.5,  # ì¢…ëª©ë‹¹ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                "total_mb_estimate": len([]) * 0.5,  # ì´ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                "safe_concurrent_limit": min(self._v_max_workers * 10, 100)
            },
            "optimization_tips": [
                "ê¸°ìˆ ì  ë¶„ì„ì€ ThreadPoolExecutor ì‚¬ìš© (I/O ì§‘ì•½ì )",
                "ëŒ€ìš©ëŸ‰ ë°°ì¹˜ëŠ” ProcessPoolExecutor ì‚¬ìš© (CPU ì§‘ì•½ì )",
                "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ì€ ê²½ìš° ë°°ì¹˜ í¬ê¸° ê°ì†Œ",
                "ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì´ ìˆëŠ” ê²½ìš° ì›Œì»¤ ìˆ˜ ì¦ê°€"
            ],
            "performance_thresholds": {
                "small_dataset": 50,   # 50ê°œ ì´í•˜: ìˆœì°¨ ì²˜ë¦¬
                "medium_dataset": 200, # 50-200ê°œ: ìŠ¤ë ˆë“œ í’€
                "large_dataset": 500   # 200ê°œ ì´ìƒ: í”„ë¡œì„¸ìŠ¤ í’€
            }
        }
    
    def adaptive_analysis(self, p_stock_list: List[Dict]) -> List[PriceAttractiveness]:
        """ì ì‘í˜• ë¶„ì„ (ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœì  ë°©ë²• ì„ íƒ)
        
        Args:
            p_stock_list: ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            _v_stock_count = len(p_stock_list)
            _v_metrics = self.get_optimization_metrics()
            
            logger.info(f"ì ì‘í˜• ë¶„ì„ ì‹œì‘: {_v_stock_count}ê°œ ì¢…ëª©")
            
            # ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœì  ë°©ë²• ì„ íƒ
            if _v_stock_count <= _v_metrics["performance_thresholds"]["small_dataset"]:
                logger.info("ì†Œê·œëª¨ ë°ì´í„° - ìˆœì°¨ ì²˜ë¦¬ ì„ íƒ")
                return super().analyze_multiple_stocks(p_stock_list)
            
            elif _v_stock_count <= _v_metrics["performance_thresholds"]["medium_dataset"]:
                logger.info("ì¤‘ê·œëª¨ ë°ì´í„° - ìŠ¤ë ˆë“œ í’€ ë³‘ë ¬ ì²˜ë¦¬ ì„ íƒ")
                return self.parallel_analyze_multiple_stocks(p_stock_list)
            
            else:
                logger.info("ëŒ€ê·œëª¨ ë°ì´í„° - í”„ë¡œì„¸ìŠ¤ í’€ ë°°ì¹˜ ì²˜ë¦¬ ì„ íƒ")
                _v_optimal_batch_size = _v_metrics["recommended_batch_size"]
                return self.batch_analyze_stocks(p_stock_list, _v_optimal_batch_size)
                
        except Exception as e:
            logger.error(f"ì ì‘í˜• ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
            return []

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    _v_parallel_analyzer = ParallelPriceAnalyzer(p_max_workers=4)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    _v_test_stocks = []
    for i in range(20):
        _v_test_stocks.append({
            "stock_code": f"00593{i:01d}",
            "stock_name": f"í…ŒìŠ¤íŠ¸ì£¼ì‹{i}",
            "current_price": 50000 + i * 1000,
            "sector": "í…ŒìŠ¤íŠ¸",
            "market_cap": 1000000000000 + i * 100000000000,
            "volatility": 0.25 + i * 0.01,
            "sector_momentum": 0.05 + i * 0.001
        })
    
    print("ë³‘ë ¬ ê°€ê²© ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰
    _v_comparison = _v_parallel_analyzer.get_performance_comparison(_v_test_stocks)
    
    print(f"\n=== ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ===")
    print(f"ì¢…ëª© ìˆ˜: {_v_comparison.get('stock_count', 0)}ê°œ")
    print(f"ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„: {_v_comparison.get('sequential_time', 0):.2f}ì´ˆ")
    print(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œê°„: {_v_comparison.get('parallel_time', 0):.2f}ì´ˆ")
    print(f"ì†ë„ í–¥ìƒ: {_v_comparison.get('speedup', 0):.2f}ë°°")
    print(f"ì¶”ì²œ ì‚¬í•­: {_v_comparison.get('recommendation', '')}")
    
    # ìµœì í™” ë©”íŠ¸ë¦­ ì¶œë ¥
    _v_metrics = _v_parallel_analyzer.get_optimization_metrics()
    print(f"\n=== ìµœì í™” ë©”íŠ¸ë¦­ ===")
    print(f"ì›Œì»¤ ìˆ˜: {_v_metrics['max_workers']}")
    print(f"ê¶Œì¥ ë°°ì¹˜ í¬ê¸°: {_v_metrics['recommended_batch_size']}")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •: {_v_metrics['memory_estimation']['total_mb_estimate']:.1f}MB")
    
    # ì ì‘í˜• ë¶„ì„ í…ŒìŠ¤íŠ¸
    print(f"\n=== ì ì‘í˜• ë¶„ì„ í…ŒìŠ¤íŠ¸ ===")
    _v_adaptive_results = _v_parallel_analyzer.adaptive_analysis(_v_test_stocks)
    print(f"ì ì‘í˜• ë¶„ì„ ê²°ê³¼: {len(_v_adaptive_results)}ê°œ ì¢…ëª© ë¶„ì„ ì™„ë£Œ") 