"""
Phase 4: AI í•™ìŠµ ì‹œìŠ¤í…œ - ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
Phase 1,2 ê²°ê³¼ ë°ì´í„°ì™€ ì‹¤ì œ ì„±ê³¼ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  AI í•™ìŠµìš© ë°ì´í„°ë¡œ ë³€í™˜
"""

import os
import json
import glob
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import numpy as np
from dataclasses import asdict

# ì¸í„°í˜ì´ìŠ¤ ë° ë°ì´í„° í´ë˜ìŠ¤ import
from core.interfaces.learning import (
    ILearningDataCollector, LearningData, 
    IFeatureEngineer, FeatureSet
)
from core.learning.config.settings import get_learning_config
from core.learning.utils.logging import get_learning_logger
from core.learning.data.storage import get_learning_storage
# ì„ì‹œ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ (ì¶”í›„ ì‹¤ì œ ì•„í‚¤í…ì²˜ë¡œ êµì²´)
def plugin(**kwargs):
    """ì„ì‹œ í”ŒëŸ¬ê·¸ì¸ ë°ì½”ë ˆì´í„°"""
    def decorator(cls):
        cls._plugin_metadata = kwargs
        return cls
    return decorator

def inject(cls):
    """ì„ì‹œ DI ë°ì½”ë ˆì´í„°"""
    return cls

logger = get_learning_logger(__name__)

@plugin(
    name="learning_data_collector",
    version="1.0.0",
    description="AI í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘ í”ŒëŸ¬ê·¸ì¸",
    author="HantuQuant",
    dependencies=["learning_config", "learning_storage"],
    category="learning"
)
class LearningDataCollector(ILearningDataCollector):
    """AI í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ"""
    
    @inject
    def __init__(self, config=None, storage=None):
        """ì´ˆê¸°í™”"""
        self._config = config or get_learning_config()
        self._storage = storage or get_learning_storage()
        self._logger = logger
        
        # ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self._project_root = Path(__file__).parent.parent.parent.parent
        self._watchlist_dir = self._project_root / "data" / "watchlist"
        self._daily_selection_dir = self._project_root / "data" / "daily_selection"
        self._stock_dir = self._project_root / "data" / "stock"
        
        self._logger.info("LearningDataCollector ì´ˆê¸°í™” ì™„ë£Œ")
    
    def collect_historical_data(self, stock_codes: List[str], 
                               start_date: str, end_date: str) -> List[LearningData]:
        """ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘"""
        try:
            self._logger.info(f"ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {len(stock_codes)}ê°œ ì¢…ëª©, {start_date} ~ {end_date}")
            
            _v_learning_data = []
            
            # ë‚ ì§œ ë²”ìœ„ ìƒì„±
            _v_date_range = pd.date_range(start=start_date, end=end_date, freq='D')
            
            for _v_date in _v_date_range:
                _v_date_str = _v_date.strftime('%Y-%m-%d')
                
                # ê° ë‚ ì§œì˜ Phase 1, 2 ê²°ê³¼ ìˆ˜ì§‘
                _v_phase1_results = self.collect_phase1_results(_v_date_str)
                _v_phase2_results = self.collect_phase2_results(_v_date_str)
                
                # ì‹¤ì œ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ (7ì¼ í›„ ì„±ê³¼)
                _v_future_date = (_v_date + timedelta(days=7)).strftime('%Y-%m-%d')
                _v_performance_data = self.collect_actual_performance(stock_codes, _v_date_str, _v_future_date)
                
                # ë°ì´í„° ë³‘í•©
                _v_merged_data = self._merge_data(_v_phase1_results, _v_phase2_results, _v_performance_data, _v_date_str)
                _v_learning_data.extend(_v_merged_data)
            
            self._logger.info(f"ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(_v_learning_data)}ê°œ ë°ì´í„°")
            return _v_learning_data
            
        except Exception as e:
            self._logger.error(f"ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []
    
    def collect_phase1_results(self, date: str) -> List[Dict]:
        """Phase 1 ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ìˆ˜ì§‘ (ìŠ¤í¬ë¦¬ë‹ í†µê³¼ ì¢…ëª©ë§Œ)"""
        try:
            _v_results = []
            
            # ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ íŒŒì¼ ê²€ìƒ‰
            _v_date_patterns = [
                datetime.strptime(date, '%Y-%m-%d').strftime('%Y%m%d'),
                datetime.strptime(date, '%Y-%m-%d').strftime('%Y-%m-%d'),
                date
            ]
            
            for _v_pattern in _v_date_patterns:
                _v_pattern_files = list(self._watchlist_dir.glob(f"*{_v_pattern}*.json"))
                _v_pattern_files.extend(list(self._watchlist_dir.glob(f"screening_results*{_v_pattern}*.json")))
                
                if _v_pattern_files:
                    for _v_file in _v_pattern_files:
                        _v_data = self._load_json_file(_v_file)
                        if _v_data and "results" in _v_data:
                            # ğŸ”¥ ì¤‘ìš”: ìŠ¤í¬ë¦¬ë‹ í†µê³¼ ì¢…ëª©ë§Œ í•™ìŠµ ëŒ€ìƒìœ¼ë¡œ í¬í•¨
                            _v_passed_stocks = [
                                stock for stock in _v_data["results"] 
                                if stock.get("overall_passed", False) == True
                            ]
                            _v_results.extend(_v_passed_stocks)
                            
                            if _v_passed_stocks:
                                self._logger.info(f"ìŠ¤í¬ë¦¬ë‹ í†µê³¼ ì¢…ëª© {len(_v_passed_stocks)}ê°œ ë°œê²¬ (ì „ì²´: {len(_v_data['results'])}ê°œ)")
                            else:
                                self._logger.warning(f"ìŠ¤í¬ë¦¬ë‹ í†µê³¼ ì¢…ëª© 0ê°œ - AI í•™ìŠµ ëŒ€ìƒ ì—†ìŒ (ì „ì²´: {len(_v_data['results'])}ê°œ)")
                    break
            
            # ê°ì‹œ ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë„ ìˆ˜ì§‘ (ìŠ¤í¬ë¦¬ë‹ í†µê³¼ë¡œ ì¶”ê°€ëœ ì¢…ëª©ë§Œ)
            _v_watchlist_files = list(self._watchlist_dir.glob("watchlist*.json"))
            for _v_file in _v_watchlist_files:
                _v_data = self._load_json_file(_v_file)
                if _v_data and "data" in _v_data and "stocks" in _v_data["data"]:
                    _v_stocks = _v_data["data"]["stocks"]
                    _v_passed_watchlist_stocks = []
                    for _v_stock in _v_stocks:
                        if (_v_stock.get("added_date", "").startswith(date) and 
                            _v_stock.get("added_reason", "") == "ìŠ¤í¬ë¦¬ë‹ í†µê³¼"):
                            _v_passed_watchlist_stocks.append(_v_stock)
                    
                    if _v_passed_watchlist_stocks:
                        _v_results.extend(_v_passed_watchlist_stocks)
                        self._logger.info(f"ê°ì‹œë¦¬ìŠ¤íŠ¸ì—ì„œ ìŠ¤í¬ë¦¬ë‹ í†µê³¼ ì¢…ëª© {len(_v_passed_watchlist_stocks)}ê°œ ì¶”ê°€")
                    else:
                        self._logger.debug(f"ê°ì‹œë¦¬ìŠ¤íŠ¸ì—ì„œ ìŠ¤í¬ë¦¬ë‹ í†µê³¼ ì¢…ëª© ì—†ìŒ")
            
            self._logger.debug(f"Phase 1 ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {date} - {len(_v_results)}ê°œ")
            return _v_results
            
        except Exception as e:
            self._logger.error(f"Phase 1 ê²°ê³¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []
    
    def collect_phase2_results(self, date: str) -> List[Dict]:
        """Phase 2 ì¼ì¼ ì„ ì • ê²°ê³¼ ìˆ˜ì§‘"""
        try:
            _v_results = []
            
            # ì¼ì¼ ì„ ì • ê²°ê³¼ íŒŒì¼ ê²€ìƒ‰
            _v_date_patterns = [
                datetime.strptime(date, '%Y-%m-%d').strftime('%Y%m%d'),
                datetime.strptime(date, '%Y-%m-%d').strftime('%Y-%m-%d'),
                date
            ]
            
            for _v_pattern in _v_date_patterns:
                _v_pattern_files = list(self._daily_selection_dir.glob(f"*{_v_pattern}*.json"))
                _v_pattern_files.extend(list(self._daily_selection_dir.glob(f"daily_selection*{_v_pattern}*.json")))
                
                if _v_pattern_files:
                    for _v_file in _v_pattern_files:
                        _v_data = self._load_json_file(_v_file)
                        if _v_data and "data" in _v_data and "selected_stocks" in _v_data["data"]:
                            _v_results.extend(_v_data["data"]["selected_stocks"])
                    break
            
            # ê°€ê²© ë¶„ì„ ê²°ê³¼ íŒŒì¼ë„ ìˆ˜ì§‘
            _v_price_files = list(self._daily_selection_dir.glob(f"price_analysis*{date}*.json"))
            for _v_file in _v_price_files:
                _v_data = self._load_json_file(_v_file)
                if _v_data and "results" in _v_data:
                    _v_results.extend(_v_data["results"])
            
            self._logger.debug(f"Phase 2 ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {date} - {len(_v_results)}ê°œ")
            return _v_results
            
        except Exception as e:
            self._logger.error(f"Phase 2 ê²°ê³¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []
    
    def collect_actual_performance(self, stock_codes: List[str], 
                                 start_date: str, end_date: str) -> Dict[str, Dict]:
        """ì‹¤ì œ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            _v_performance_data = {}
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” APIë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
            for _v_stock_code in stock_codes:
                _v_performance_data[_v_stock_code] = self._simulate_performance(_v_stock_code, start_date, end_date)
            
            self._logger.debug(f"ì‹¤ì œ ì„±ê³¼ ìˆ˜ì§‘ ì™„ë£Œ: {len(_v_performance_data)}ê°œ ì¢…ëª©")
            return _v_performance_data
            
        except Exception as e:
            self._logger.error(f"ì‹¤ì œ ì„±ê³¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def validate_data_quality(self, data: List[LearningData]) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        try:
            _v_quality_report = {
                "total_records": len(data),
                "valid_records": 0,
                "invalid_records": 0,
                "missing_fields": {},
                "data_types": {},
                "value_ranges": {},
                "quality_score": 0.0
            }
            
            for _v_record in data:
                _v_is_valid = True
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not _v_record.stock_code or not _v_record.stock_name:
                    _v_is_valid = False
                    _v_quality_report["missing_fields"]["stock_info"] = _v_quality_report["missing_fields"].get("stock_info", 0) + 1
                
                # Phase 1 ë°ì´í„° ê²€ì¦
                if not _v_record.phase1_data:
                    _v_is_valid = False
                    _v_quality_report["missing_fields"]["phase1_data"] = _v_quality_report["missing_fields"].get("phase1_data", 0) + 1
                
                # Phase 2 ë°ì´í„° ê²€ì¦
                if not _v_record.phase2_data:
                    _v_is_valid = False
                    _v_quality_report["missing_fields"]["phase2_data"] = _v_quality_report["missing_fields"].get("phase2_data", 0) + 1
                
                # ì‹¤ì œ ì„±ê³¼ ë°ì´í„° ê²€ì¦
                if not _v_record.actual_performance:
                    _v_is_valid = False
                    _v_quality_report["missing_fields"]["actual_performance"] = _v_quality_report["missing_fields"].get("actual_performance", 0) + 1
                
                if _v_is_valid:
                    _v_quality_report["valid_records"] += 1
                else:
                    _v_quality_report["invalid_records"] += 1
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            if _v_quality_report["total_records"] > 0:
                _v_quality_report["quality_score"] = _v_quality_report["valid_records"] / _v_quality_report["total_records"]
            
            self._logger.info(f"ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ: {_v_quality_report['quality_score']:.2%} í’ˆì§ˆ")
            return _v_quality_report
            
        except Exception as e:
            self._logger.error(f"ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _merge_data(self, phase1_results: List[Dict], phase2_results: List[Dict], 
                   performance_data: Dict[str, Dict], date: str) -> List[LearningData]:
        """ë°ì´í„° ë³‘í•©"""
        try:
            _v_merged_data = []
            
            # Phase 1 ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
            for _v_phase1 in phase1_results:
                _v_stock_code = _v_phase1.get("stock_code", "")
                _v_stock_name = _v_phase1.get("stock_name", "")
                
                if not _v_stock_code:
                    continue
                
                # Phase 2 ê²°ê³¼ ì°¾ê¸°
                _v_phase2_data = {}
                for _v_phase2 in phase2_results:
                    if _v_phase2.get("stock_code") == _v_stock_code:
                        _v_phase2_data = _v_phase2
                        break
                
                # ì‹¤ì œ ì„±ê³¼ ë°ì´í„° ì°¾ê¸°
                _v_performance = performance_data.get(_v_stock_code, {})
                
                # ì‹œì¥ ìƒí™© íŒë‹¨
                _v_market_condition = self._determine_market_condition(date)
                
                # LearningData ê°ì²´ ìƒì„±
                _v_learning_data = LearningData(
                    stock_code=_v_stock_code,
                    stock_name=_v_stock_name,
                    date=date,
                    phase1_data=_v_phase1,
                    phase2_data=_v_phase2_data,
                    actual_performance=_v_performance,
                    market_condition=_v_market_condition,
                    metadata={
                        "merge_timestamp": datetime.now().isoformat(),
                        "data_sources": {
                            "phase1": bool(_v_phase1),
                            "phase2": bool(_v_phase2_data),
                            "performance": bool(_v_performance)
                        }
                    }
                )
                
                _v_merged_data.append(_v_learning_data)
            
            return _v_merged_data
            
        except Exception as e:
            self._logger.error(f"ë°ì´í„° ë³‘í•© ì˜¤ë¥˜: {e}")
            return []
    
    def _load_json_file(self, file_path: Path) -> Optional[Dict]:
        """JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self._logger.error(f"JSON íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {file_path}: {e}")
            return None
    
    def _simulate_performance(self, stock_code: str, start_date: str, end_date: str) -> Dict[str, float]:
        """ì„±ê³¼ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” API ì‚¬ìš©)"""
        try:
            # ì‹œë“œ ì„¤ì •ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ ìƒì„±
            np.random.seed(hash(stock_code + start_date) % 1000)
            
            # ê¸°ë³¸ ìˆ˜ìµë¥  ìƒì„± (-20% ~ +30% ë²”ìœ„)
            _v_base_return = np.random.normal(0.05, 0.15)  # í‰ê·  5%, í‘œì¤€í¸ì°¨ 15%
            _v_base_return = max(-0.2, min(0.3, _v_base_return))  # ë²”ìœ„ ì œí•œ
            
            # ë¦¬ìŠ¤í¬ ì§€í‘œ ìƒì„±
            _v_volatility = np.random.uniform(0.1, 0.4)
            _v_max_drawdown = np.random.uniform(0.05, 0.25)
            _v_sharpe_ratio = _v_base_return / _v_volatility if _v_volatility > 0 else 0
            
            # êµ¬ê°„ë³„ ìˆ˜ìµë¥  ìƒì„±
            _v_returns = {
                "1d_return": np.random.normal(0.01, 0.03),
                "3d_return": np.random.normal(0.02, 0.05),
                "7d_return": _v_base_return,
                "14d_return": np.random.normal(_v_base_return * 1.5, 0.1),
                "30d_return": np.random.normal(_v_base_return * 2.0, 0.15)
            }
            
            # ë¦¬ìŠ¤í¬ ì§€í‘œ
            _v_risk_metrics = {
                "volatility": _v_volatility,
                "max_drawdown": _v_max_drawdown,
                "sharpe_ratio": _v_sharpe_ratio,
                "var_95": np.random.uniform(0.03, 0.08),
                "beta": np.random.uniform(0.5, 1.5)
            }
            
            # ê±°ë˜ ì •ë³´
            _v_trading_info = {
                "avg_volume": np.random.uniform(100000, 5000000),
                "volume_increase": np.random.uniform(0.8, 2.5),
                "price_change": _v_base_return,
                "trading_days": 7
            }
            
            return {
                **_v_returns,
                **_v_risk_metrics,
                **_v_trading_info
            }
            
        except Exception as e:
            self._logger.error(f"ì„±ê³¼ ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")
            return {}
    
    def _determine_market_condition(self, date: str) -> str:
        """ì‹œì¥ ìƒí™© íŒë‹¨"""
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ë¶„ì„
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
            _v_date_hash = hash(date) % 100
            
            if _v_date_hash < 30:
                return "bull_market"
            elif _v_date_hash < 60:
                return "sideways"
            elif _v_date_hash < 85:
                return "bear_market"
            else:
                return "volatile"
                
        except Exception:
            return "neutral"
    
    def get_data_statistics(self, start_date: str, end_date: str) -> Dict[str, Any]:
        """ë°ì´í„° í†µê³„ ì •ë³´ ì¡°íšŒ"""
        try:
            _v_stats = {
                "date_range": {
                    "start": start_date,
                    "end": end_date
                },
                "file_counts": {
                    "phase1_files": len(list(self._watchlist_dir.glob("*.json"))),
                    "phase2_files": len(list(self._daily_selection_dir.glob("*.json"))),
                    "stock_files": len(list(self._stock_dir.glob("*.json")))
                },
                "data_coverage": {},
                "quality_metrics": {}
            }
            
            # ë‚ ì§œë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ í™•ì¸
            _v_date_range = pd.date_range(start=start_date, end=end_date, freq='D')
            _v_coverage = {}
            
            for _v_date in _v_date_range:
                _v_date_str = _v_date.strftime('%Y-%m-%d')
                _v_phase1_count = len(self.collect_phase1_results(_v_date_str))
                _v_phase2_count = len(self.collect_phase2_results(_v_date_str))
                
                _v_coverage[_v_date_str] = {
                    "phase1_count": _v_phase1_count,
                    "phase2_count": _v_phase2_count,
                    "has_data": _v_phase1_count > 0 or _v_phase2_count > 0
                }
            
            _v_stats["data_coverage"] = _v_coverage
            
            # ì „ì²´ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
            _v_total_days = len(_v_date_range)
            _v_days_with_data = sum(1 for d in _v_coverage.values() if d["has_data"])
            _v_stats["quality_metrics"]["coverage_rate"] = _v_days_with_data / _v_total_days if _v_total_days > 0 else 0
            
            return _v_stats
            
        except Exception as e:
            self._logger.error(f"ë°ì´í„° í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_data_collector = None

def get_data_collector() -> LearningDataCollector:
    """ë°ì´í„° ìˆ˜ì§‘ê¸° ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _data_collector
    if _data_collector is None:
        _data_collector = LearningDataCollector()
    return _data_collector 