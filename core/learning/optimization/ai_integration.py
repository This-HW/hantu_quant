"""
AI í•™ìŠµ ëª¨ë¸ í†µí•© ë° ë°°í¬ ì‹œìŠ¤í…œ

Phase 4ì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ì—¬ ì™„ì „í•œ AI í•™ìŠµ ì‹œìŠ¤í…œì„ êµ¬ì¶•
"""

import numpy as np
import json
import os
import pickle
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum


class RestrictedUnpickler(pickle.Unpickler):
    """
    ë³´ì•ˆ ê°•í™”ëœ Unpickler - í—ˆìš©ëœ ëª¨ë“ˆ/í´ë˜ìŠ¤ë§Œ ì—­ì§ë ¬í™”
    ì•…ì˜ì ì¸ pickle íŒŒì¼ë¡œë¶€í„° ë³´í˜¸
    """
    # í—ˆìš©ëœ ëª¨ë“ˆ ëª©ë¡
    ALLOWED_MODULES = {
        'numpy', 'numpy.core.multiarray', 'numpy.core.numeric',
        'pandas', 'pandas.core.frame', 'pandas.core.series',
        'sklearn', 'xgboost', 'lightgbm',
        'builtins', 'collections', 'datetime',
    }

    # í—ˆìš©ëœ í´ë˜ìŠ¤ ëª©ë¡
    ALLOWED_CLASSES = {
        'dict', 'list', 'tuple', 'set', 'frozenset',
        'int', 'float', 'str', 'bool', 'bytes',
        'datetime', 'date', 'timedelta',
        'ndarray', 'dtype', 'DataFrame', 'Series',
    }

    def find_class(self, module: str, name: str):
        """í—ˆìš©ëœ ëª¨ë“ˆ/í´ë˜ìŠ¤ë§Œ ë¡œë“œ"""
        # ëª¨ë“ˆ ê²€ì¦
        module_base = module.split('.')[0]
        if module_base not in self.ALLOWED_MODULES and module not in self.ALLOWED_MODULES:
            raise pickle.UnpicklingError(
                f"ë³´ì•ˆ: í—ˆìš©ë˜ì§€ ì•Šì€ ëª¨ë“ˆ '{module}' ë¡œë“œ ì‹œë„ê°€ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

        return super().find_class(module, name)


def safe_pickle_load(file_path: str, max_size_mb: int = 100) -> Any:
    """
    ë³´ì•ˆ ê°•í™”ëœ pickle ë¡œë“œ í•¨ìˆ˜

    Args:
        file_path: ë¡œë“œí•  pickle íŒŒì¼ ê²½ë¡œ
        max_size_mb: ìµœëŒ€ í—ˆìš© íŒŒì¼ í¬ê¸° (MB)

    Returns:
        ì—­ì§ë ¬í™”ëœ ê°ì²´

    Raises:
        ValueError: íŒŒì¼ í¬ê¸° ì´ˆê³¼ ë˜ëŠ” ê²€ì¦ ì‹¤íŒ¨
        pickle.UnpicklingError: í—ˆìš©ë˜ì§€ ì•Šì€ í´ë˜ìŠ¤ ë¡œë“œ ì‹œë„
    """
    # íŒŒì¼ í¬ê¸° ê²€ì¦
    file_size = os.path.getsize(file_path)
    max_size_bytes = max_size_mb * 1024 * 1024

    if file_size > max_size_bytes:
        raise ValueError(f"íŒŒì¼ í¬ê¸°({file_size / 1024 / 1024:.1f}MB)ê°€ ìµœëŒ€ í—ˆìš© í¬ê¸°({max_size_mb}MB)ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")

    # ì œí•œëœ Unpicklerë¡œ ë¡œë“œ
    with open(file_path, 'rb') as f:
        return RestrictedUnpickler(f).load()

from ...utils.logging import get_logger
from .genetic_optimizer import GeneticOptimizer, GeneticConfig
from .bayesian_optimizer import BayesianOptimizer, BayesianConfig
from .backtest_automation import BacktestEngine, ValidationSystem

# ëª¨ë¸ ê´€ë ¨ import
try:
    from ..models.pattern_learner import PatternLearner, LearningConfig
    from ..models.prediction_engine import PredictionEngine, PredictionConfig
    from ..models.feedback_system import FeedbackSystem
    from ..features.feature_selector import FeatureExtractor
    from ..analysis.daily_performance import DailyPerformanceAnalyzer
    MODEL_IMPORTS_AVAILABLE = True
except ImportError:
    MODEL_IMPORTS_AVAILABLE = False
    logger = get_logger(__name__)
    logger.warning("ì¼ë¶€ ëª¨ë¸ import ì‹¤íŒ¨ - ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥")

logger = get_logger(__name__)

class DeploymentStatus(Enum):
    """ë°°í¬ ìƒíƒœ"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"
    ROLLBACK = "rollback"
    MAINTENANCE = "maintenance"

class ModelStatus(Enum):
    """ëª¨ë¸ ìƒíƒœ"""
    TRAINING = "training"
    READY = "ready"
    DEPLOYED = "deployed"
    DEPRECATED = "deprecated"
    FAILED = "failed"

@dataclass
class DeploymentConfig:
    """ë°°í¬ ì„¤ì •"""
    model_version: str = "1.0.0"
    environment: str = "staging"
    auto_rollback: bool = True
    performance_threshold: float = 0.8
    monitoring_interval: int = 3600  # 1ì‹œê°„
    backup_models: int = 3
    health_check_timeout: int = 30

@dataclass
class ModelMetadata:
    """ëª¨ë¸ ë©”íƒ€ë°ì´í„°"""
    model_id: str
    model_type: str
    version: str
    training_date: datetime
    accuracy: float
    performance_metrics: Dict[str, float]
    status: ModelStatus
    file_path: str
    description: str = ""

@dataclass
class DeploymentResult:
    """ë°°í¬ ê²°ê³¼"""
    deployment_id: str
    model_metadata: ModelMetadata
    deployment_status: DeploymentStatus
    deployment_time: datetime
    success: bool
    error_message: Optional[str] = None
    rollback_model: Optional[str] = None
    performance_score: Optional[float] = None

class ModelRegistry:
    """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self, registry_dir: str = "data/model_registry"):
        """
        ì´ˆê¸°í™”
        
        Args:
            registry_dir: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë””ë ‰í† ë¦¬
        """
        self._logger = logger
        self._registry_dir = registry_dir
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(registry_dir, exist_ok=True)
        
        # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
        self._models = {}
        self._model_history = []
        
        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ
        self._load_registry()
        
        self._logger.info("ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def register_model(self, model_metadata: ModelMetadata) -> bool:
        """ëª¨ë¸ ë“±ë¡"""
        try:
            # ëª¨ë¸ íŒŒì¼ ê²€ì¦
            if not os.path.exists(model_metadata.file_path):
                self._logger.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_metadata.file_path}", exc_info=True)
                return False
            
            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì¶”ê°€
            self._models[model_metadata.model_id] = model_metadata
            self._model_history.append({
                'action': 'register',
                'model_id': model_metadata.model_id,
                'timestamp': datetime.now(),
                'version': model_metadata.version
            })
            
            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥
            self._save_registry()
            
            self._logger.info(f"ëª¨ë¸ ë“±ë¡ ì™„ë£Œ: {model_metadata.model_id} v{model_metadata.version}")
            return True
            
        except Exception as e:
            self._logger.error(f"ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    def get_model(self, model_id: str) -> Optional[ModelMetadata]:
        """ëª¨ë¸ ì¡°íšŒ"""
        return self._models.get(model_id)
    
    def get_models_by_type(self, model_type: str) -> List[ModelMetadata]:
        """íƒ€ì…ë³„ ëª¨ë¸ ì¡°íšŒ"""
        return [
            model for model in self._models.values()
            if model.model_type == model_type
        ]
    
    def get_latest_model(self, model_type: str) -> Optional[ModelMetadata]:
        """ìµœì‹  ëª¨ë¸ ì¡°íšŒ"""
        type_models = self.get_models_by_type(model_type)
        if not type_models:
            return None
        
        # í›ˆë ¨ ë‚ ì§œ ê¸°ì¤€ ìµœì‹  ëª¨ë¸ ë°˜í™˜
        return max(type_models, key=lambda m: m.training_date)
    
    def update_model_status(self, model_id: str, status: ModelStatus) -> bool:
        """ëª¨ë¸ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if model_id in self._models:
            self._models[model_id].status = status
            self._model_history.append({
                'action': 'status_update',
                'model_id': model_id,
                'timestamp': datetime.now(),
                'new_status': status.value
            })
            self._save_registry()
            return True
        return False
    
    def _save_registry(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥"""
        try:
            registry_file = os.path.join(self._registry_dir, "model_registry.json")
            
            registry_data = {
                'models': {},
                'history': self._model_history
            }
            
            # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì§ë ¬í™”
            for model_id, metadata in self._models.items():
                model_dict = asdict(metadata)
                model_dict['training_date'] = metadata.training_date.isoformat()
                model_dict['status'] = metadata.status.value
                registry_data['models'][model_id] = model_dict
            
            with open(registry_file, 'w', encoding='utf-8') as f:
                json.dump(registry_data, f, ensure_ascii=False, indent=2, default=str)
                
        except Exception as e:
            self._logger.error(f"ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
    
    def _load_registry(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        try:
            registry_file = os.path.join(self._registry_dir, "model_registry.json")
            
            if os.path.exists(registry_file):
                with open(registry_file, 'r', encoding='utf-8') as f:
                    registry_data = json.load(f)
                
                # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì—­ì§ë ¬í™”
                for model_id, model_dict in registry_data.get('models', {}).items():
                    model_dict['training_date'] = datetime.fromisoformat(model_dict['training_date'])
                    model_dict['status'] = ModelStatus(model_dict['status'])
                    
                    metadata = ModelMetadata(**model_dict)
                    self._models[model_id] = metadata
                
                self._model_history = registry_data.get('history', [])
                
                self._logger.info(f"ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ ì™„ë£Œ: {len(self._models)}ê°œ ëª¨ë¸")
                
        except Exception as e:
            self._logger.error(f"ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)

class IntegrationManager:
    """í†µí•© ê´€ë¦¬ì"""
    
    def __init__(self, data_dir: str = "data/integration"):
        """
        ì´ˆê¸°í™”
        
        Args:
            data_dir: í†µí•© ë°ì´í„° ë””ë ‰í† ë¦¬
        """
        self._logger = logger
        self._data_dir = data_dir
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(data_dir, exist_ok=True)
        
        # ì»´í¬ë„ŒíŠ¸ë“¤
        self._parameter_manager = None
        self._pattern_learner = None
        self._prediction_engine = None
        self._feedback_system = None
        self._genetic_optimizer = None
        self._bayesian_optimizer = None
        self._backtest_engine = None
        self._validation_system = None
        
        # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
        self._model_registry = ModelRegistry()
        
        # í†µí•© ìƒíƒœ
        self._integration_status = {}
        self._is_integrated = False
        
        self._logger.info("í†µí•© ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
    
    def initialize_components(self) -> bool:
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            self._logger.info("AI í•™ìŠµ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘")
            
            # 1. íŒŒë¼ë¯¸í„° ê´€ë¦¬ì
            from .parameter_manager import get_parameter_manager
            self._parameter_manager = get_parameter_manager()
            self._integration_status['parameter_manager'] = True
            
            # 2. ì„±ê³¼ ë¶„ì„ê¸° (Mock ë˜ëŠ” ì‹¤ì œ)
            if MODEL_IMPORTS_AVAILABLE:
                from ..analysis.daily_performance import get_performance_analyzer
                performance_analyzer = get_performance_analyzer()
                self._integration_status['performance_analyzer'] = True
            else:
                # Mock ì„±ê³¼ ë¶„ì„ê¸°
                performance_analyzer = self._create_mock_performance_analyzer()
                self._integration_status['performance_analyzer'] = False
            
            # 3. í”¼ì²˜ ì¶”ì¶œê¸° (Mock ë˜ëŠ” ì‹¤ì œ)
            if MODEL_IMPORTS_AVAILABLE:
                try:
                    from ..features.feature_selector import FeatureExtractor
                    feature_extractor = FeatureExtractor()
                    self._integration_status['feature_extractor'] = True
                except:
                    feature_extractor = self._create_mock_feature_extractor()
                    self._integration_status['feature_extractor'] = False
            else:
                feature_extractor = self._create_mock_feature_extractor()
                self._integration_status['feature_extractor'] = False
            
            # 4. íŒ¨í„´ í•™ìŠµê¸°
            if MODEL_IMPORTS_AVAILABLE:
                try:
                    from ..models.pattern_learner import get_pattern_learner
                    self._pattern_learner = get_pattern_learner(feature_extractor, performance_analyzer)
                    self._integration_status['pattern_learner'] = True
                except:
                    self._pattern_learner = self._create_mock_pattern_learner()
                    self._integration_status['pattern_learner'] = False
            else:
                self._pattern_learner = self._create_mock_pattern_learner()
                self._integration_status['pattern_learner'] = False
            
            # 5. ì˜ˆì¸¡ ì—”ì§„
            if MODEL_IMPORTS_AVAILABLE:
                try:
                    from ..models.prediction_engine import get_prediction_engine
                    self._prediction_engine = get_prediction_engine(self._pattern_learner)
                    self._integration_status['prediction_engine'] = True
                except:
                    self._prediction_engine = self._create_mock_prediction_engine()
                    self._integration_status['prediction_engine'] = False
            else:
                self._prediction_engine = self._create_mock_prediction_engine()
                self._integration_status['prediction_engine'] = False
            
            # 6. í”¼ë“œë°± ì‹œìŠ¤í…œ
            if MODEL_IMPORTS_AVAILABLE:
                try:
                    from ..models.feedback_system import get_feedback_system
                    self._feedback_system = get_feedback_system(self._prediction_engine, performance_analyzer)
                    self._integration_status['feedback_system'] = True
                except:
                    self._feedback_system = self._create_mock_feedback_system()
                    self._integration_status['feedback_system'] = False
            else:
                self._feedback_system = self._create_mock_feedback_system()
                self._integration_status['feedback_system'] = False
            
            # 7. ìµœì í™”ê¸°ë“¤
            def mock_fitness_function(param_set):
                return np.random.uniform(0.5, 0.9)  # Mock ì í•©ë„ í•¨ìˆ˜
            
            try:
                self._genetic_optimizer = GeneticOptimizer(
                    self._parameter_manager, mock_fitness_function
                )
                self._integration_status['genetic_optimizer'] = True
            except:
                self._integration_status['genetic_optimizer'] = False
            
            try:
                self._bayesian_optimizer = BayesianOptimizer(
                    self._parameter_manager, mock_fitness_function
                )
                self._integration_status['bayesian_optimizer'] = True
            except:
                self._integration_status['bayesian_optimizer'] = False
            
            # 8. ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
            try:
                self._backtest_engine = BacktestEngine()
                self._validation_system = ValidationSystem()
                self._integration_status['backtest_system'] = True
            except:
                self._integration_status['backtest_system'] = False
            
            # í†µí•© ì™„ë£Œ ì²´í¬
            successful_components = sum(1 for status in self._integration_status.values() if status)
            total_components = len(self._integration_status)
            
            self._is_integrated = successful_components >= total_components * 0.7  # 70% ì´ìƒ ì„±ê³µ
            
            self._logger.info(f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {successful_components}/{total_components} ì„±ê³µ")
            return self._is_integrated
            
        except Exception as e:
            self._logger.error(f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    def _create_mock_performance_analyzer(self):
        """Mock ì„±ê³¼ ë¶„ì„ê¸°"""
        class MockPerformanceAnalyzer:
            def __init__(self):
                self._performance_history = []
        return MockPerformanceAnalyzer()
    
    def _create_mock_feature_extractor(self):
        """Mock í”¼ì²˜ ì¶”ì¶œê¸°"""
        class MockFeatureExtractor:
            def _calculate_slope_features(self, data):
                return {f"slope_{i}": np.random.random() for i in range(9)}
            def _calculate_volume_features(self, data):
                return {f"volume_{i}": np.random.random() for i in range(8)}
        return MockFeatureExtractor()
    
    def _create_mock_pattern_learner(self):
        """Mock íŒ¨í„´ í•™ìŠµê¸°"""
        class MockPatternLearner:
            def predict_pattern(self, stock_code, date=None):
                return {
                    'success_probability': np.random.uniform(0.4, 0.8),
                    'confidence': np.random.uniform(0.6, 0.9),
                    'individual_predictions': {'mock_model': np.random.uniform(0.5, 0.8)}
                }
        return MockPatternLearner()
    
    def _create_mock_prediction_engine(self):
        """Mock ì˜ˆì¸¡ ì—”ì§„"""
        class MockPredictionEngine:
            def predict_stock(self, stock_code, stock_name=None, date=None):
                return None  # ê°„ë‹¨í•œ Mock
            def update_prediction_result(self, prediction_id, actual_return):
                return True
            def get_recent_predictions(self, days=7):
                return []
        return MockPredictionEngine()
    
    def _create_mock_feedback_system(self):
        """Mock í”¼ë“œë°± ì‹œìŠ¤í…œ"""
        class MockFeedbackSystem:
            def collect_feedback(self, prediction_id, actual_return):
                return True
            def evaluate_model_performance(self, days=30):
                return {}
        return MockFeedbackSystem()
    
    def create_integrated_model(self, model_name: str, strategy_name: str) -> Optional[ModelMetadata]:
        """í†µí•© ëª¨ë¸ ìƒì„±"""
        if not self._is_integrated:
            self._logger.error("ì‹œìŠ¤í…œì´ í†µí•©ë˜ì§€ ì•ŠìŒ")
            return None
        
        try:
            self._logger.info(f"í†µí•© ëª¨ë¸ ìƒì„± ì‹œì‘: {model_name}")
            
            # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
            model_dir = os.path.join(self._data_dir, "models", model_name)
            os.makedirs(model_dir, exist_ok=True)
            
            # í†µí•© ëª¨ë¸ êµ¬ì„±
            integrated_model = {
                'metadata': {
                    'model_name': model_name,
                    'strategy_name': strategy_name,
                    'creation_date': datetime.now(),
                    'version': '1.0.0',
                    'components': list(self._integration_status.keys())
                },
                'components': {
                    'parameter_manager': self._serialize_component(self._parameter_manager),
                    'pattern_learner': self._serialize_component(self._pattern_learner),
                    'prediction_engine': self._serialize_component(self._prediction_engine),
                    'feedback_system': self._serialize_component(self._feedback_system)
                },
                'configuration': {
                    'genetic_config': asdict(GeneticConfig()) if self._genetic_optimizer else None,
                    'bayesian_config': asdict(BayesianConfig()) if self._bayesian_optimizer else None,
                    'integration_status': self._integration_status
                }
            }
            
            # ëª¨ë¸ íŒŒì¼ ì €ì¥
            model_file = os.path.join(model_dir, f"{model_name}_integrated.pkl")
            with open(model_file, 'wb') as f:
                pickle.dump(integrated_model, f)
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥
            metadata_file = os.path.join(model_dir, f"{model_name}_metadata.json")
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(integrated_model['metadata'], f, ensure_ascii=False, indent=2, default=str)
            
            # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ìƒì„±
            model_metadata = ModelMetadata(
                model_id=f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                model_type="integrated_ai_system",
                version="1.0.0",
                training_date=datetime.now(),
                accuracy=0.85,  # ì¶”ì • ì •í™•ë„
                performance_metrics={
                    'integration_score': sum(1 for s in self._integration_status.values() if s) / len(self._integration_status),
                    'component_count': len(self._integration_status),
                    'success_rate': 0.85
                },
                status=ModelStatus.READY,
                file_path=model_file,
                description=f"í†µí•© AI í•™ìŠµ ì‹œìŠ¤í…œ - {strategy_name} ì „ëµìš©"
            )
            
            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
            if self._model_registry.register_model(model_metadata):
                self._logger.info(f"í†µí•© ëª¨ë¸ ìƒì„± ì™„ë£Œ: {model_metadata.model_id}")
                return model_metadata
            else:
                self._logger.error("ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ì‹¤íŒ¨")
                return None
            
        except Exception as e:
            self._logger.error(f"í†µí•© ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return None
    
    def _serialize_component(self, component) -> Dict[str, Any]:
        """ì»´í¬ë„ŒíŠ¸ ì§ë ¬í™”"""
        if component is None:
            return {'type': 'none', 'data': None}
        
        try:
            component_type = type(component).__name__
            
            # ê°„ë‹¨í•œ ìƒíƒœ ì •ë³´ë§Œ ì €ì¥
            if hasattr(component, 'get_learning_summary'):
                data = component.get_learning_summary()
            elif hasattr(component, 'get_optimization_summary'):
                data = component.get_optimization_summary()
            elif hasattr(component, 'get_feedback_summary'):
                data = component.get_feedback_summary()
            else:
                data = {'status': 'active', 'type': component_type}
            
            return {
                'type': component_type,
                'data': data,
                'serialized_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self._logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì§ë ¬í™” ì‹¤íŒ¨: {e}")
            return {'type': 'unknown', 'data': None, 'error': str(e)}
    
    def deploy_integrated_model(self, model_metadata: ModelMetadata,
                               config: DeploymentConfig = None) -> DeploymentResult:
        """í†µí•© ëª¨ë¸ ë°°í¬"""
        if config is None:
            config = DeploymentConfig()
        
        deployment_id = f"deploy_{model_metadata.model_id}_{datetime.now().strftime('%H%M%S')}"
        
        try:
            self._logger.info(f"ëª¨ë¸ ë°°í¬ ì‹œì‘: {deployment_id}")
            
            # ë°°í¬ ì „ ê²€ì¦
            if not self._validate_model_for_deployment(model_metadata):
                return DeploymentResult(
                    deployment_id=deployment_id,
                    model_metadata=model_metadata,
                    deployment_status=DeploymentStatus.DEVELOPMENT,
                    deployment_time=datetime.now(),
                    success=False,
                    error_message="ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨"
                )
            
            # ë°±ì—… ìƒì„±
            backup_success = self._create_model_backup(model_metadata)
            if not backup_success:
                self._logger.warning("ëª¨ë¸ ë°±ì—… ì‹¤íŒ¨ - ë°°í¬ ê³„ì† ì§„í–‰")
            
            # ëª¨ë¸ íŒŒì¼ ë°°í¬ ìœ„ì¹˜ë¡œ ë³µì‚¬
            deployment_path = self._copy_model_to_deployment(model_metadata, config)
            if not deployment_path:
                return DeploymentResult(
                    deployment_id=deployment_id,
                    model_metadata=model_metadata,
                    deployment_status=DeploymentStatus.DEVELOPMENT,
                    deployment_time=datetime.now(),
                    success=False,
                    error_message="ëª¨ë¸ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨"
                )
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self._model_registry.update_model_status(model_metadata.model_id, ModelStatus.DEPLOYED)
            
            # ì„±ê³µì ì¸ ë°°í¬ ê²°ê³¼
            deployment_result = DeploymentResult(
                deployment_id=deployment_id,
                model_metadata=model_metadata,
                deployment_status=DeploymentStatus.PRODUCTION if config.environment == "production" else DeploymentStatus.STAGING,
                deployment_time=datetime.now(),
                success=True,
                performance_score=model_metadata.accuracy
            )
            
            self._logger.info(f"ëª¨ë¸ ë°°í¬ ì™„ë£Œ: {deployment_id}")
            return deployment_result
            
        except Exception as e:
            self._logger.error(f"ëª¨ë¸ ë°°í¬ ì‹¤íŒ¨: {e}", exc_info=True)
            return DeploymentResult(
                deployment_id=deployment_id,
                model_metadata=model_metadata,
                deployment_status=DeploymentStatus.DEVELOPMENT,
                deployment_time=datetime.now(),
                success=False,
                error_message=str(e)
            )
    
    def _validate_model_for_deployment(self, model_metadata: ModelMetadata) -> bool:
        """ë°°í¬ìš© ëª¨ë¸ ê²€ì¦"""
        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(model_metadata.file_path):
                return False
            
            # ìµœì†Œ ì •í™•ë„ í™•ì¸
            if model_metadata.accuracy < 0.7:
                return False
            
            # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (ë³´ì•ˆ ê°•í™”ëœ ë¡œë” ì‚¬ìš©)
            model_data = safe_pickle_load(model_metadata.file_path)
            if 'metadata' not in model_data:
                return False
            
            return True
            
        except Exception as e:
            self._logger.error(f"ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    def _create_model_backup(self, model_metadata: ModelMetadata) -> bool:
        """ëª¨ë¸ ë°±ì—… ìƒì„±"""
        try:
            backup_dir = os.path.join(self._data_dir, "backups")
            os.makedirs(backup_dir, exist_ok=True)
            
            backup_filename = f"{model_metadata.model_id}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            backup_path = os.path.join(backup_dir, backup_filename)
            
            # íŒŒì¼ ë³µì‚¬
            import shutil
            shutil.copy2(model_metadata.file_path, backup_path)
            
            self._logger.info(f"ëª¨ë¸ ë°±ì—… ìƒì„±: {backup_path}")
            return True
            
        except Exception as e:
            self._logger.error(f"ëª¨ë¸ ë°±ì—… ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    def _copy_model_to_deployment(self, model_metadata: ModelMetadata,
                                 config: DeploymentConfig) -> Optional[str]:
        """ëª¨ë¸ì„ ë°°í¬ ìœ„ì¹˜ë¡œ ë³µì‚¬"""
        try:
            deployment_dir = os.path.join(self._data_dir, "deployed", config.environment)
            os.makedirs(deployment_dir, exist_ok=True)
            
            deployment_filename = f"{model_metadata.model_type}_{config.model_version}.pkl"
            deployment_path = os.path.join(deployment_dir, deployment_filename)
            
            # íŒŒì¼ ë³µì‚¬
            import shutil
            shutil.copy2(model_metadata.file_path, deployment_path)
            
            self._logger.info(f"ëª¨ë¸ ë°°í¬ ë³µì‚¬ ì™„ë£Œ: {deployment_path}")
            return deployment_path
            
        except Exception as e:
            self._logger.error(f"ëª¨ë¸ ë°°í¬ ë³µì‚¬ ì‹¤íŒ¨: {e}", exc_info=True)
            return None
    
    def get_integration_status(self) -> Dict[str, Any]:
        """í†µí•© ìƒíƒœ ì¡°íšŒ"""
        return {
            'is_integrated': self._is_integrated,
            'components_status': self._integration_status,
            'successful_components': sum(1 for s in self._integration_status.values() if s),
            'total_components': len(self._integration_status),
            'models_registered': len(self._model_registry._models),
            'integration_score': sum(1 for s in self._integration_status.values() if s) / len(self._integration_status) if self._integration_status else 0
        }
    
    def run_end_to_end_test(self, strategy_name: str = "momentum_strategy") -> Dict[str, Any]:
        """ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self._logger.info("AI í•™ìŠµ ì‹œìŠ¤í…œ ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        test_results = {
            'test_id': f"e2e_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'start_time': datetime.now(),
            'components_tested': [],
            'test_results': {},
            'overall_success': False
        }
        
        try:
            # 1. íŒŒë¼ë¯¸í„° ê´€ë¦¬ í…ŒìŠ¤íŠ¸
            if self._parameter_manager:
                param_test = self._test_parameter_manager(strategy_name)
                test_results['test_results']['parameter_manager'] = param_test
                test_results['components_tested'].append('parameter_manager')
            
            # 2. íŒ¨í„´ í•™ìŠµ í…ŒìŠ¤íŠ¸
            if self._pattern_learner:
                pattern_test = self._test_pattern_learner()
                test_results['test_results']['pattern_learner'] = pattern_test
                test_results['components_tested'].append('pattern_learner')
            
            # 3. ì˜ˆì¸¡ ì—”ì§„ í…ŒìŠ¤íŠ¸
            if self._prediction_engine:
                prediction_test = self._test_prediction_engine()
                test_results['test_results']['prediction_engine'] = prediction_test
                test_results['components_tested'].append('prediction_engine')
            
            # 4. í†µí•© ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
            integration_test = self._test_model_integration(strategy_name)
            test_results['test_results']['model_integration'] = integration_test
            test_results['components_tested'].append('model_integration')
            
            # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
            successful_tests = sum(1 for result in test_results['test_results'].values() if result.get('success', False))
            total_tests = len(test_results['test_results'])
            test_results['success_rate'] = successful_tests / total_tests if total_tests > 0 else 0
            test_results['overall_success'] = test_results['success_rate'] >= 0.8
            
            test_results['end_time'] = datetime.now()
            test_results['duration'] = (test_results['end_time'] - test_results['start_time']).total_seconds()
            
            self._logger.info(f"ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì„±ê³µë¥ : {test_results['success_rate']:.1%}")
            return test_results
            
        except Exception as e:
            self._logger.error(f"ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
            test_results['error'] = str(e)
            test_results['end_time'] = datetime.now()
            return test_results
    
    def _test_parameter_manager(self, strategy_name: str) -> Dict[str, Any]:
        """íŒŒë¼ë¯¸í„° ê´€ë¦¬ì í…ŒìŠ¤íŠ¸"""
        try:
            # ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„± í…ŒìŠ¤íŠ¸
            param_set = self._parameter_manager.create_random_parameter_set(strategy_name)
            success = param_set is not None
            
            return {
                'success': success,
                'message': 'íŒŒë¼ë¯¸í„° ìƒì„± ì„±ê³µ' if success else 'íŒŒë¼ë¯¸í„° ìƒì„± ì‹¤íŒ¨',
                'parameter_count': len(param_set.parameters) if param_set else 0
            }
        except Exception as e:
            return {'success': False, 'message': str(e)}
    
    def _test_pattern_learner(self) -> Dict[str, Any]:
        """íŒ¨í„´ í•™ìŠµê¸° í…ŒìŠ¤íŠ¸"""
        try:
            # ê°„ë‹¨í•œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
            prediction = self._pattern_learner.predict_pattern("005930")
            success = 'success_probability' in prediction
            
            return {
                'success': success,
                'message': 'íŒ¨í„´ ì˜ˆì¸¡ ì„±ê³µ' if success else 'íŒ¨í„´ ì˜ˆì¸¡ ì‹¤íŒ¨',
                'prediction_keys': list(prediction.keys())
            }
        except Exception as e:
            return {'success': False, 'message': str(e)}
    
    def _test_prediction_engine(self) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
        try:
            # ì˜ˆì¸¡ ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            success = self._prediction_engine is not None
            
            return {
                'success': success,
                'message': 'ì˜ˆì¸¡ ì—”ì§„ í™œì„±' if success else 'ì˜ˆì¸¡ ì—”ì§„ ë¹„í™œì„±'
            }
        except Exception as e:
            return {'success': False, 'message': str(e)}
    
    def _test_model_integration(self, strategy_name: str) -> Dict[str, Any]:
        """ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸"""
        try:
            # í†µí•© ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
            model_metadata = self.create_integrated_model(f"test_model_{datetime.now().strftime('%H%M%S')}", strategy_name)
            success = model_metadata is not None
            
            return {
                'success': success,
                'message': 'í†µí•© ëª¨ë¸ ìƒì„± ì„±ê³µ' if success else 'í†µí•© ëª¨ë¸ ìƒì„± ì‹¤íŒ¨',
                'model_id': model_metadata.model_id if model_metadata else None
            }
        except Exception as e:
            return {'success': False, 'message': str(e)}

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_integration_manager = None

def get_integration_manager() -> IntegrationManager:
    """í†µí•© ê´€ë¦¬ì ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _integration_manager
    if _integration_manager is None:
        _integration_manager = IntegrationManager()
    return _integration_manager

def deploy_phase4_ai_system(strategy_name: str = "momentum_strategy") -> Dict[str, Any]:
    """Phase 4 AI ì‹œìŠ¤í…œ ì „ì²´ ë°°í¬"""
    logger.info("ğŸš€ Phase 4 AI í•™ìŠµ ì‹œìŠ¤í…œ ì „ì²´ ë°°í¬ ì‹œì‘")
    
    deployment_results = {
        'deployment_id': f"phase4_deploy_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        'start_time': datetime.now(),
        'strategy_name': strategy_name,
        'steps_completed': [],
        'overall_success': False
    }
    
    try:
        # 1. í†µí•© ê´€ë¦¬ì ì´ˆê¸°í™”
        integration_manager = get_integration_manager()
        deployment_results['steps_completed'].append('integration_manager_init')
        
        # 2. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        components_initialized = integration_manager.initialize_components()
        deployment_results['components_initialized'] = components_initialized
        deployment_results['steps_completed'].append('components_init')
        
        # 3. ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸
        test_results = integration_manager.run_end_to_end_test(strategy_name)
        deployment_results['test_results'] = test_results
        deployment_results['steps_completed'].append('end_to_end_test')
        
        # 4. í†µí•© ëª¨ë¸ ìƒì„±
        model_metadata = integration_manager.create_integrated_model("phase4_ai_system", strategy_name)
        if model_metadata:
            deployment_results['model_created'] = True
            deployment_results['model_id'] = model_metadata.model_id
            deployment_results['steps_completed'].append('model_creation')
            
            # 5. ëª¨ë¸ ë°°í¬
            deployment_config = DeploymentConfig(
                model_version="1.0.0",
                environment="staging"
            )
            deploy_result = integration_manager.deploy_integrated_model(model_metadata, deployment_config)
            deployment_results['model_deployed'] = deploy_result.success
            deployment_results['deployment_status'] = deploy_result.deployment_status.value
            deployment_results['steps_completed'].append('model_deployment')
        else:
            deployment_results['model_created'] = False
        
        # 6. í†µí•© ìƒíƒœ í™•ì¸
        integration_status = integration_manager.get_integration_status()
        deployment_results['integration_status'] = integration_status
        deployment_results['steps_completed'].append('status_check')
        
        # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        deployment_results['overall_success'] = (
            components_initialized and
            test_results.get('overall_success', False) and
            deployment_results.get('model_created', False) and
            deployment_results.get('model_deployed', False)
        )
        
        deployment_results['end_time'] = datetime.now()
        deployment_results['total_duration'] = (deployment_results['end_time'] - deployment_results['start_time']).total_seconds()
        
        if deployment_results['overall_success']:
            logger.info("ğŸ‰ Phase 4 AI ì‹œìŠ¤í…œ ë°°í¬ ì„±ê³µ!")
        else:
            logger.warning("âš ï¸ Phase 4 AI ì‹œìŠ¤í…œ ë°°í¬ ë¶€ë¶„ ì„±ê³µ")
        
        return deployment_results
        
    except Exception as e:
        logger.error(f"âŒ Phase 4 AI ì‹œìŠ¤í…œ ë°°í¬ ì‹¤íŒ¨: {e}", exc_info=True)
        deployment_results['error'] = str(e)
        deployment_results['end_time'] = datetime.now()
        return deployment_results 