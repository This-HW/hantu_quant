# Phase 4: AI í•™ìŠµ ì‹œìŠ¤í…œ ìƒì„¸ ì„¤ê³„ ë¬¸ì„œ

## ğŸ“‹ ê°œìš”

**TODO ì°¸ì¡°**: 2.1-2.8 (Phase 4 AI í•™ìŠµ ì‹œìŠ¤í…œ êµ¬í˜„)

**ëª©í‘œ**: Phase 1(ì¢…ëª© ìŠ¤í¬ë¦¬ë‹)ê³¼ Phase 2(ì¼ì¼ ì„ ì •) ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ AI í•™ìŠµì„ í†µí•´ ì ì§„ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” ì‹œìŠ¤í…œ

**ë°©ì‹**: ì§ì ‘ í•™ìŠµ ëª¨ë¸ êµ¬ì¶• (ì™¸ë¶€ AI API ì‚¬ìš© ì•ˆí•¨)

**ê¸°ìˆ  ìŠ¤íƒ**: 
- scikit-learn (ê¸°ë³¸ ë¨¸ì‹ ëŸ¬ë‹)
- XGBoost (ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…)
- TensorFlow/PyTorch (ë”¥ëŸ¬ë‹)
- Optuna (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”)

## ğŸ—‚ï¸ TODO ê¸°ë°˜ êµ¬í˜„ ê³„íš

### TODO 2.1: Phase 4 ê¸°ë³¸ êµ¬ì¡° ì„¤ì •
- `core/learning/` ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •
- ê¸°ë³¸ í´ë˜ìŠ¤ ë° ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- ë¡œê¹… ë° ì„¤ì • ì‹œìŠ¤í…œ êµ¬ì¶•
- ë°ì´í„° ì €ì¥ì†Œ êµ¬ì¡° ì„¤ê³„

### TODO 2.2: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„
- ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•
- ë°ì´í„° ì •ê·œí™” ë° í´ë¦¬ë‹ ë¡œì§
- í”¼ì²˜ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- ë°ì´í„° ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬

### TODO 2.3: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹œìŠ¤í…œ êµ¬í˜„ (17ê°œ í”¼ì²˜)
- ê¸°ìš¸ê¸° í”¼ì²˜ êµ¬í˜„ (9ê°œ)
- ë³¼ë¥¨ í”¼ì²˜ êµ¬í˜„ (8ê°œ)
- í”¼ì²˜ ì„ íƒ ë° ì¤‘ìš”ë„ ë¶„ì„

### TODO 2.4: ì¼ì¼ ì„±ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„
- ì„ ì • ì¢…ëª© ì„±ê³¼ ì¶”ì  ì‹œìŠ¤í…œ
- ìˆ˜ìµë¥  ë° ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
- ì „ëµë³„ ì„±ê³¼ ë¹„êµ ë¶„ì„

### TODO 2.5: íŒ¨í„´ í•™ìŠµ ì—”ì§„ êµ¬í˜„
- ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ì¸ì‹ ì‹œìŠ¤í…œ
- ì‹œì¥ ìƒí™©ë³„ íŒ¨í„´ ë¶„ì„
- ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ ë° ì ìš©

### TODO 2.6: íŒŒë¼ë¯¸í„° ìë™ ìµœì í™” ì‹œìŠ¤í…œ êµ¬í˜„
- ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìµœì í™”
- A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ êµ¬í˜„
- ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì • ì‹œìŠ¤í…œ

### TODO 2.7: ë°±í…ŒìŠ¤íŠ¸ ìë™í™” ì‹œìŠ¤í…œ êµ¬í˜„
- ì¼ì¼ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œìŠ¤í…œ
- ì„±ê³¼ ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±
- ì „ëµ ì—…ë°ì´íŠ¸ ìë™í™”

### TODO 2.8: AI í•™ìŠµ ëª¨ë¸ í†µí•© ë° ë°°í¬
- Phase 1/2 ì‹œìŠ¤í…œì— AI ëª¨ë¸ í†µí•©
- ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ êµ¬í˜„

## ğŸ§  AI í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ìƒì„¸ ì„¤ëª…

### 1. ì•™ìƒë¸” í•™ìŠµ (Ensemble Learning)

#### ğŸ¯ ëª©ì 
Phase 1ê³¼ Phase 2ì—ì„œ ì„ ì •í•œ ì¢…ëª©ì˜ **ì„±ê³µ í™•ë¥  ì˜ˆì¸¡**ê³¼ **ìˆ˜ìµë¥  ì˜ˆì¸¡**

#### ğŸ“Š ì ìš© ì˜ì—­
- **Phase 1**: ìŠ¤í¬ë¦¬ë‹ëœ ì¢…ëª©ì´ ì‹¤ì œë¡œ ì¢‹ì€ ì„±ê³¼ë¥¼ ë‚¼ì§€ ì˜ˆì¸¡
- **Phase 2**: ì„ ì •ëœ ì¢…ëª©ì˜ ë‹¨ê¸° ìˆ˜ìµë¥  ì˜ˆì¸¡

#### ğŸ”§ êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ë²•

##### A. Random Forest (ëœë¤ í¬ë ˆìŠ¤íŠ¸)
```python
# ì¢…ëª© ì„ ì • ì •í™•ë„ ì˜ˆì¸¡
class StockSelectionPredictor:
    def __init__(self):
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
    
    def prepare_features(self, stock_data):
        """
        íŠ¹ì§• ë°ì´í„° ì¤€ë¹„ (TODO 2.3 ê¸°ë°˜)
        - ì¬ë¬´ ì§€í‘œ: ROE, PER, PBR, ë¶€ì±„ë¹„ìœ¨ ë“±
        - ê¸°ìˆ  ì§€í‘œ: RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ ë“±
        - ì‹œì¥ ì§€í‘œ: ê±°ë˜ëŸ‰, ë³€ë™ì„±, ìƒëŒ€ê°•ë„ ë“±
        - ê¸°ìš¸ê¸° í”¼ì²˜: 9ê°œ í”¼ì²˜ (TODO 1.5 ê¸°ë°˜)
        - ë³¼ë¥¨ í”¼ì²˜: 8ê°œ í”¼ì²˜ (TODO 1.6 ê¸°ë°˜)
        """
        features = {
            'financial_score': stock_data['roe'] * 0.3 + stock_data['per_rank'] * 0.2,
            'technical_score': stock_data['rsi'] * 0.4 + stock_data['macd'] * 0.3,
            'momentum_score': stock_data['relative_strength'] * 0.5,
            'market_condition': self.get_market_condition(),
            'slope_features': self.extract_slope_features(stock_data),  # TODO 2.3
            'volume_features': self.extract_volume_features(stock_data),  # TODO 2.3
```

##### B. XGBoost (ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…)
```python
# ìˆ˜ìµë¥  ì˜ˆì¸¡
class ReturnPredictor:
    def __init__(self):
        self.model = XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        )
    
    def prepare_time_series_features(self, price_data):
        """
        ì‹œê³„ì—´ íŠ¹ì§• ìƒì„±
        - ì´ë™í‰ê· : 5ì¼, 20ì¼, 60ì¼
        - ëª¨ë©˜í…€: 1ì£¼ì¼, 1ê°œì›” ìˆ˜ìµë¥ 
        - ë³€ë™ì„±: í‘œì¤€í¸ì°¨, ATR
        """
        features = {
            'ma5_ratio': price_data['close'] / price_data['ma5'],
            'ma20_ratio': price_data['close'] / price_data['ma20'],
            'ma60_ratio': price_data['close'] / price_data['ma60'],
            'rsi': price_data['rsi'],
            'macd': price_data['macd'],
            'volume_ratio': price_data['volume'] / price_data['volume_ma20'],
            'momentum_1m': price_data['return_1m'],
            'momentum_3m': price_data['return_3m'],
            'volatility': price_data['volatility'],
            'market_correlation': price_data['market_correlation'],
            
            # === ìƒˆë¡œ ì¶”ê°€ëœ ê¸°ìš¸ê¸° ì§€í‘œ ===
            'price_slope_5d': self.calculate_price_slope(price_data, 5),
            'price_slope_20d': self.calculate_price_slope(price_data, 20),
            'ma5_slope': self.calculate_ma_slope(price_data, 5, 3),
            'ma20_slope': self.calculate_ma_slope(price_data, 20, 5),
            'ma60_slope': self.calculate_ma_slope(price_data, 60, 10),
            'slope_acceleration': self.calculate_slope_acceleration(price_data),
            'trend_consistency': self.check_trend_consistency(price_data),
            'slope_angle': self.calculate_slope_angle(price_data),
            'slope_strength_score': self.get_slope_strength_score(price_data),
            
            # === í–¥ìƒëœ ê±°ë˜ëŸ‰ ì§€í‘œ ===
            'volume_price_correlation': self.calculate_volume_price_correlation(price_data),
            'volume_price_divergence': self.calculate_volume_price_divergence(price_data),
            'volume_momentum_score': self.calculate_volume_momentum_score(price_data),
            'relative_volume_strength': self.calculate_relative_volume_strength(price_data),
            'volume_rank_percentile': self.calculate_volume_rank_percentile(price_data),
            'volume_intensity': self.calculate_volume_intensity(price_data),
            'volume_cluster_count': self.calculate_volume_cluster_count(price_data),
            'volume_anomaly_score': self.calculate_volume_anomaly_score(price_data)
        }
        
        return features
    
    def calculate_price_slope(self, price_data: pd.DataFrame, days: int) -> float:
        """ê°€ê²© ê¸°ìš¸ê¸° ê³„ì‚°"""
        if len(price_data) < days:
            return 0.0
        
        recent_prices = price_data['close'].tail(days)
        x = np.arange(len(recent_prices))
        slope = np.polyfit(x, recent_prices.values, 1)[0]
        
        # ì •ê·œí™” (í˜„ì¬ê°€ ëŒ€ë¹„ ë°±ë¶„ìœ¨)
        current_price = recent_prices.iloc[-1]
        normalized_slope = (slope / current_price) * 100 if current_price != 0 else 0.0
        
        return normalized_slope
    
    def calculate_ma_slope(self, price_data: pd.DataFrame, ma_period: int, slope_days: int) -> float:
        """ì´ë™í‰ê·  ê¸°ìš¸ê¸° ê³„ì‚°"""
        if len(price_data) < ma_period + slope_days:
            return 0.0
        
        ma = price_data['close'].rolling(window=ma_period).mean()
        recent_ma = ma.dropna().tail(slope_days)
        
        if len(recent_ma) < slope_days:
            return 0.0
        
        x = np.arange(len(recent_ma))
        slope = np.polyfit(x, recent_ma.values, 1)[0]
        
        # ì •ê·œí™”
        current_ma = recent_ma.iloc[-1]
        normalized_slope = (slope / current_ma) * 100 if current_ma != 0 else 0.0
        
        return normalized_slope
    
    def calculate_slope_acceleration(self, price_data: pd.DataFrame) -> float:
        """ê¸°ìš¸ê¸° ê°€ì†ë„ ê³„ì‚°"""
        if len(price_data) < 10:
            return 0.0
        
        current_slope = self.calculate_price_slope(price_data, 5)
        previous_slope = self.calculate_price_slope(price_data.iloc[:-5], 5)
        
        return current_slope - previous_slope
    
    def check_trend_consistency(self, price_data: pd.DataFrame) -> float:
        """ì¶”ì„¸ ì¼ê´€ì„± í™•ì¸ (0 ë˜ëŠ” 1)"""
        if len(price_data) < 70:
            return 0.0
        
        short_slope = self.calculate_ma_slope(price_data, 5, 3)
        medium_slope = self.calculate_ma_slope(price_data, 20, 5)
        long_slope = self.calculate_ma_slope(price_data, 60, 10)
        
        # ëª¨ë“  ê¸°ìš¸ê¸°ê°€ ê°™ì€ ë°©í–¥ì¸ì§€ í™•ì¸
        positive_trend = short_slope > 0 and medium_slope > 0 and long_slope > 0
        negative_trend = short_slope < 0 and medium_slope < 0 and long_slope < 0
        
        return 1.0 if (positive_trend or negative_trend) else 0.0
    
    def calculate_slope_angle(self, price_data: pd.DataFrame) -> float:
        """ê¸°ìš¸ê¸° ê°ë„ ê³„ì‚°"""
        slope = self.calculate_price_slope(price_data, 5)
        actual_slope = slope / 100
        angle = np.arctan(actual_slope) * 180 / np.pi
        
        return angle
    
    def get_slope_strength_score(self, price_data: pd.DataFrame) -> float:
        """ê¸°ìš¸ê¸° ê°•ë„ ì ìˆ˜ (0-100)"""
        slope = self.calculate_price_slope(price_data, 5)
        
        if slope > 1.0:
            return 100.0  # strong_up
        elif slope > 0.3:
            return 75.0   # weak_up
        elif slope > -0.3:
            return 50.0   # neutral
        elif slope > -1.0:
            return 25.0   # weak_down
        else:
            return 0.0    # strong_down
    
    def calculate_volume_price_correlation(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰-ê°€ê²© ë³€í™” ìƒê´€ê´€ê³„ ê³„ì‚°"""
        if len(price_data) < 20:
            return 0.0
        
        price_changes = price_data['close'].pct_change().tail(20)
        volume_changes = price_data['volume'].pct_change().tail(20)
        
        correlation = price_changes.corr(volume_changes)
        return correlation if not pd.isna(correlation) else 0.0
    
    def calculate_volume_price_divergence(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰-ê°€ê²© ë‹¤ì´ë²„ì „ìŠ¤ ì ìˆ˜ (0-100)"""
        if len(price_data) < 20:
            return 0.0
        
        # ìµœê·¼ 10ì¼ê³¼ ì´ì „ 10ì¼ ë¹„êµ
        recent_data = price_data.tail(10)
        previous_data = price_data.iloc[-20:-10]
        
        # ê°€ê²© ì¶”ì„¸
        recent_price_trend = (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / recent_data['close'].iloc[0]
        previous_price_trend = (previous_data['close'].iloc[-1] - previous_data['close'].iloc[0]) / previous_data['close'].iloc[0]
        
        # ê±°ë˜ëŸ‰ ì¶”ì„¸
        recent_volume_trend = (recent_data['volume'].mean() - previous_data['volume'].mean()) / previous_data['volume'].mean()
        
        # ë‹¤ì´ë²„ì „ìŠ¤ ì ìˆ˜
        price_direction = 1 if recent_price_trend > previous_price_trend else -1
        volume_direction = 1 if recent_volume_trend > 0 else -1
        
        if price_direction != volume_direction:
            return 75.0 if price_direction > 0 else 25.0  # bearish/bullish divergence
        else:
            return 50.0  # neutral
    
    def calculate_volume_momentum_score(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ ëª¨ë©˜í…€ ì ìˆ˜ (0-100)"""
        if len(price_data) < 20:
            return 50.0
        
        # ë‹¨ê¸° ë° ì¥ê¸° ê±°ë˜ëŸ‰ í‰ê· 
        short_volume_avg = price_data['volume'].tail(5).mean()
        long_volume_avg = price_data['volume'].tail(20).mean()
        
        # ê°€ê²© ë³€í™”ìœ¨
        short_price_change = (price_data['close'].iloc[-1] - price_data['close'].iloc[-5]) / price_data['close'].iloc[-5]
        long_price_change = (price_data['close'].iloc[-1] - price_data['close'].iloc[-20]) / price_data['close'].iloc[-20]
        
        # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        volume_ratio = short_volume_avg / long_volume_avg if long_volume_avg > 0 else 1.0
        
        # ëª¨ë©˜í…€ ìŠ¤ì½”ì–´
        momentum_score = (short_price_change + long_price_change) * volume_ratio
        
        # 0-100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        if momentum_score > 0.05:
            return 100.0  # strong_bullish
        elif momentum_score > 0.02:
            return 75.0   # moderate_bullish
        elif momentum_score > -0.02:
            return 50.0   # neutral
        elif momentum_score > -0.05:
            return 25.0   # moderate_bearish
        else:
            return 0.0    # strong_bearish
    
    def calculate_relative_volume_strength(self, price_data: pd.DataFrame) -> float:
        """ìƒëŒ€ì  ê±°ë˜ëŸ‰ ê°•ë„ (í˜„ì¬ ê±°ë˜ëŸ‰ / í‰ê·  ê±°ë˜ëŸ‰)"""
        if len(price_data) < 20:
            return 1.0
        
        current_volume = price_data['volume'].iloc[-1]
        avg_volume = price_data['volume'].tail(20).mean()
        
        return current_volume / avg_volume if avg_volume > 0 else 1.0
    
    def calculate_volume_rank_percentile(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ ìˆœìœ„ ë°±ë¶„ìœ„ (0-100)"""
        if len(price_data) < 60:
            return 50.0
        
        volumes = price_data['volume'].tail(60)
        current_volume = volumes.iloc[-1]
        
        percentile = (volumes < current_volume).sum() / len(volumes) * 100
        return percentile
    
    def calculate_volume_intensity(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ ê°•ë„ (ê±°ë˜ëŸ‰ ë¹„ìœ¨ / ê°€ê²© ë³€í™”ìœ¨)"""
        if len(price_data) < 20:
            return 0.0
        
        # ê°€ê²© ë³€í™”ìœ¨
        price_change = price_data['close'].pct_change().iloc[-1]
        
        # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        current_volume = price_data['volume'].iloc[-1]
        avg_volume = price_data['volume'].tail(20).mean()
        volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1.0
        
        # ê°•ë„ ê³„ì‚°
        if abs(price_change) > 0.02:
            intensity = volume_ratio / abs(price_change)
        else:
            intensity = volume_ratio
        
        return intensity
    
    def calculate_volume_cluster_count(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜"""
        if len(price_data) < 20:
            return 0.0
        
        # ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„° ê°ì§€ (í‰ê·  ëŒ€ë¹„ 1.5ë°° ì´ìƒì¸ ì—°ì† êµ¬ê°„)
        avg_volume = price_data['volume'].mean()
        high_volume_points = price_data['volume'] > (avg_volume * 1.5)
        
        # ì—°ì† êµ¬ê°„ ê°œìˆ˜ ê³„ì‚°
        clusters = 0
        in_cluster = False
        
        for is_high in high_volume_points:
            if is_high and not in_cluster:
                clusters += 1
                in_cluster = True
            elif not is_high:
                in_cluster = False
        
        return float(clusters)
    
    def calculate_volume_anomaly_score(self, price_data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ ì´ìƒì¹˜ ì ìˆ˜ (0-100)"""
        if len(price_data) < 20:
            return 0.0
        
        volumes = price_data['volume'].tail(20)
        mean_volume = volumes.mean()
        std_volume = volumes.std()
        
        if std_volume == 0:
            return 0.0
        
        # í˜„ì¬ ê±°ë˜ëŸ‰ì˜ Z-score
        current_volume = volumes.iloc[-1]
        z_score = (current_volume - mean_volume) / std_volume
        
        # ì´ìƒì¹˜ ì ìˆ˜ (ë†’ì€ ê±°ë˜ëŸ‰ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        if z_score > 3:
            return 100.0
        elif z_score > 2:
            return 75.0
        elif z_score > 1:
            return 50.0
        else:
            return 0.0
```

##### C. LSTM (ì‹œê³„ì—´ ë”¥ëŸ¬ë‹)
```python
# ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
class TimeSeriesPatternLearner:
    def __init__(self):
        self.model = tf.keras.Sequential([
            tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(60, 5)),
            tf.keras.layers.LSTM(50, return_sequences=False),
            tf.keras.layers.Dense(25),
            tf.keras.layers.Dense(1)
        ])
        self.model.compile(optimizer='adam', loss='mse')
    
    def prepare_sequences(self, price_data, sequence_length=60):
        """
        60ì¼ ê°€ê²© ë°ì´í„°ë¡œ ë‹¤ìŒ ì£¼ ìˆ˜ìµë¥  ì˜ˆì¸¡
        - ì…ë ¥: 60ì¼ê°„ì˜ [ì¢…ê°€, ê±°ë˜ëŸ‰, RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ]
        - ì¶œë ¥: 1ì£¼ì¼ í›„ ìˆ˜ìµë¥ 
        """
        sequences = []
        targets = []
        
        for i in range(sequence_length, len(price_data) - 7):
            # 60ì¼ ì‹œí€€ìŠ¤
            sequence = price_data[i-sequence_length:i]
            # 1ì£¼ì¼ í›„ ìˆ˜ìµë¥ 
            target = (price_data[i+7]['close'] / price_data[i]['close']) - 1
            
            sequences.append(sequence)
            targets.append(target)
        
        return np.array(sequences), np.array(targets)
    
    def train(self, historical_price_data):
        X, y = self.prepare_sequences(historical_price_data)
        self.model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)
```

### 2. ê°•í™”í•™ìŠµ (Reinforcement Learning)

#### ğŸ¯ ëª©ì 
Phase 1, 2ì˜ **íŒŒë¼ë¯¸í„° ìë™ ìµœì í™”** (ê°€ì¤‘ì¹˜, ì„ê³„ê°’ ë“±)

#### ğŸ“Š ì ìš© ì˜ì—­
- **Phase 1**: ì¬ë¬´/ê¸°ìˆ /ëª¨ë©˜í…€ ê°€ì¤‘ì¹˜ ìë™ ì¡°ì •
- **Phase 2**: ë§¤ë ¥ë„ ì„ê³„ê°’, ë¦¬ìŠ¤í¬ ì„ê³„ê°’ ìë™ ì¡°ì •

#### ğŸ”§ êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ë²•

```python
# PPO (Proximal Policy Optimization) ê¸°ë°˜ íŒŒë¼ë¯¸í„° ìµœì í™”
class ParameterOptimizationAgent:
    def __init__(self):
        # í™˜ê²½ ì •ì˜
        self.state_dim = 10  # ì‹œì¥ ìƒí™©, ìµœê·¼ ì„±ê³¼ ë“±
        self.action_dim = 6   # ì¡°ì •í•  íŒŒë¼ë¯¸í„° ê°œìˆ˜
        
        # PPO ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.agent = PPO(
            state_dim=self.state_dim,
            action_dim=self.action_dim,
            lr=0.0003
        )
    
    def get_state(self):
        """
        í˜„ì¬ ìƒíƒœ ì •ì˜
        - ì‹œì¥ ìƒí™© (ìƒìŠ¹/í•˜ë½/íš¡ë³´)
        - ìµœê·¼ 1ì£¼ì¼ ì„±ê³¼
        - ìµœê·¼ 1ê°œì›” ì„±ê³¼
        - ì‹œì¥ ë³€ë™ì„±
        - ì„ ì • ì¢…ëª© ìˆ˜
        """
        return np.array([
            self.market_condition,      # 0: í•˜ë½, 1: íš¡ë³´, 2: ìƒìŠ¹
            self.recent_1w_performance, # ìµœê·¼ 1ì£¼ì¼ í‰ê·  ìˆ˜ìµë¥ 
            self.recent_1m_performance, # ìµœê·¼ 1ê°œì›” í‰ê·  ìˆ˜ìµë¥ 
            self.market_volatility,     # ì‹œì¥ ë³€ë™ì„±
            self.selection_count,       # ì„ ì • ì¢…ëª© ìˆ˜
            self.hit_ratio,            # ì ì¤‘ë¥ 
            self.sharpe_ratio,         # ìƒ¤í”„ ë¹„ìœ¨
            self.max_drawdown,         # ìµœëŒ€ ë‚™í­
            self.sector_diversity,     # ì„¹í„° ë‹¤ì–‘ì„±
            self.momentum_trend        # ëª¨ë©˜í…€ íŠ¸ë Œë“œ
        ])
    
    def take_action(self, action):
        """
        í–‰ë™ = íŒŒë¼ë¯¸í„° ì¡°ì •
        - action[0]: Phase1 ì¬ë¬´ ê°€ì¤‘ì¹˜ ì¡°ì • (-0.1 ~ +0.1)
        - action[1]: Phase1 ê¸°ìˆ  ê°€ì¤‘ì¹˜ ì¡°ì •
        - action[2]: Phase1 ëª¨ë©˜í…€ ê°€ì¤‘ì¹˜ ì¡°ì •
        - action[3]: Phase2 ë§¤ë ¥ë„ ì„ê³„ê°’ ì¡°ì •
        - action[4]: Phase2 ë¦¬ìŠ¤í¬ ì„ê³„ê°’ ì¡°ì •
        - action[5]: Phase2 ì„¹í„°ë³„ ì œí•œ ì¡°ì •
        """
        # í˜„ì¬ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
        current_params = self.get_current_parameters()
        
        # í–‰ë™ì— ë”°ë¼ íŒŒë¼ë¯¸í„° ì¡°ì •
        new_params = {
            'phase1_financial_weight': current_params['phase1_financial_weight'] + action[0] * 0.1,
            'phase1_technical_weight': current_params['phase1_technical_weight'] + action[1] * 0.1,
            'phase1_momentum_weight': current_params['phase1_momentum_weight'] + action[2] * 0.1,
            'phase2_min_attractiveness': current_params['phase2_min_attractiveness'] + action[3] * 5,
            'phase2_max_risk': current_params['phase2_max_risk'] + action[4] * 5,
            'phase2_sector_limit': max(1, current_params['phase2_sector_limit'] + int(action[5] * 2))
        }
        
        # íŒŒë¼ë¯¸í„° ì œì•½ ì¡°ê±´ ì ìš©
        new_params = self.apply_constraints(new_params)
        
        # ìƒˆ íŒŒë¼ë¯¸í„°ë¡œ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
        self.update_system_parameters(new_params)
        
        return new_params
    
    def calculate_reward(self, performance_data):
        """
        ë³´ìƒ ê³„ì‚°
        - ì£¼ ë³´ìƒ: ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥  (ìƒ¤í”„ ë¹„ìœ¨)
        - ë³´ì¡° ë³´ìƒ: ì ì¤‘ë¥ , ë‹¤ì–‘ì„± ë“±
        """
        sharpe_ratio = performance_data['sharpe_ratio']
        hit_ratio = performance_data['hit_ratio']
        max_drawdown = performance_data['max_drawdown']
        
        # ìƒ¤í”„ ë¹„ìœ¨ì´ ì£¼ìš” ë³´ìƒ
        reward = sharpe_ratio * 10
        
        # ì ì¤‘ë¥  ë³´ë„ˆìŠ¤
        if hit_ratio > 0.7:
            reward += 5
        
        # ìµœëŒ€ ë‚™í­ í˜ë„í‹°
        if max_drawdown > 0.15:
            reward -= 10
        
        return reward
    
    def train_step(self):
        """
        ì¼ì¼ í•™ìŠµ ìŠ¤í…
        1. í˜„ì¬ ìƒíƒœ ê´€ì°°
        2. í–‰ë™ ì„ íƒ (íŒŒë¼ë¯¸í„° ì¡°ì •)
        3. 1ì¼ í›„ ì„±ê³¼ ì¸¡ì •
        4. ë³´ìƒ ê³„ì‚°
        5. ì •ì±… ì—…ë°ì´íŠ¸
        """
        state = self.get_state()
        action = self.agent.select_action(state)
        new_params = self.take_action(action)
        
        # 1ì¼ í›„ ì„±ê³¼ ì¸¡ì • (ë‹¤ìŒë‚  ì‹¤í–‰ í›„)
        # ì´ ë¶€ë¶„ì€ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬ë¨
        
    def update_policy(self, state, action, reward, next_state):
        """ì •ì±… ì—…ë°ì´íŠ¸"""
        self.agent.update(state, action, reward, next_state)
```

### 3. ìœ ì „ ì•Œê³ ë¦¬ì¦˜ (Genetic Algorithm)

#### ğŸ¯ ëª©ì 
**íŒŒë¼ë¯¸í„° ì¡°í•©ì˜ ì „ì—­ ìµœì í™”** (ê°•í™”í•™ìŠµì´ ì§€ì—­ ìµœì í•´ì— ë¹ ì§ˆ ë•Œ ë³´ì™„)

#### ğŸ“Š ì ìš© ì˜ì—­
- ì£¼ë§ì— ì‹¤í–‰í•˜ì—¬ íŒŒë¼ë¯¸í„° ëŒ€í­ ì¡°ì •
- ê°•í™”í•™ìŠµìœ¼ë¡œ ì°¾ê¸° ì–´ë ¤ìš´ íŒŒë¼ë¯¸í„° ì¡°í•© íƒìƒ‰

#### ğŸ”§ êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ë²•

```python
# ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ìµœì í™”
class GeneticParameterOptimizer:
    def __init__(self, population_size=50, generations=100):
        self.population_size = population_size
        self.generations = generations
        self.mutation_rate = 0.1
        self.crossover_rate = 0.8
    
    def create_individual(self):
        """
        ê°œì²´ ìƒì„± (íŒŒë¼ë¯¸í„° ì¡°í•©)
        - ê° íŒŒë¼ë¯¸í„°ëŠ” ìœ íš¨ ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ ìƒì„±
        """
        individual = {
            'phase1_financial_weight': random.uniform(0.2, 0.6),
            'phase1_technical_weight': random.uniform(0.2, 0.6),
            'phase1_momentum_weight': random.uniform(0.1, 0.4),
            'phase2_min_attractiveness': random.uniform(50, 80),
            'phase2_max_risk': random.uniform(30, 60),
            'phase2_min_confidence': random.uniform(0.3, 0.7),
            'phase2_sector_limit': random.randint(2, 6)
        }
        
        # ê°€ì¤‘ì¹˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
        weight_sum = (individual['phase1_financial_weight'] + 
                     individual['phase1_technical_weight'] + 
                     individual['phase1_momentum_weight'])
        
        individual['phase1_financial_weight'] /= weight_sum
        individual['phase1_technical_weight'] /= weight_sum
        individual['phase1_momentum_weight'] /= weight_sum
        
        return individual
    
    def evaluate_fitness(self, individual):
        """
        ì í•©ë„ í‰ê°€ (ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰)
        - ìµœê·¼ 6ê°œì›” ë°ì´í„°ë¡œ ë°±í…ŒìŠ¤íŠ¸
        - ìƒ¤í”„ ë¹„ìœ¨, ìµœëŒ€ ë‚™í­, ì ì¤‘ë¥  ì¢…í•© í‰ê°€
        """
        # íŒŒë¼ë¯¸í„° ì ìš©í•˜ì—¬ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        backtest_results = self.run_backtest(individual)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        sharpe_ratio = backtest_results['sharpe_ratio']
        max_drawdown = backtest_results['max_drawdown']
        hit_ratio = backtest_results['hit_ratio']
        
        # ì í•©ë„ = ìƒ¤í”„ ë¹„ìœ¨ * ì ì¤‘ë¥  - ìµœëŒ€ ë‚™í­ í˜ë„í‹°
        fitness = sharpe_ratio * hit_ratio - max_drawdown * 2
        
        return fitness
    
    def crossover(self, parent1, parent2):
        """êµë°° (ê· ë“± êµë°°)"""
        child1 = {}
        child2 = {}
        
        for key in parent1.keys():
            if random.random() < 0.5:
                child1[key] = parent1[key]
                child2[key] = parent2[key]
            else:
                child1[key] = parent2[key]
                child2[key] = parent1[key]
        
        return child1, child2
    
    def mutate(self, individual):
        """ëŒì—°ë³€ì´ (ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€)"""
        for key, value in individual.items():
            if random.random() < self.mutation_rate:
                if isinstance(value, float):
                    # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
                    noise = random.gauss(0, 0.05)
                    individual[key] = max(0.01, min(1.0, value + noise))
                elif isinstance(value, int):
                    # ì •ìˆ˜ëŠ” Â±1 ë³€ê²½
                    individual[key] = max(1, min(10, value + random.choice([-1, 1])))
        
        return individual
    
    def optimize(self):
        """ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰"""
        # ì´ˆê¸° ì§‘ë‹¨ ìƒì„±
        population = [self.create_individual() for _ in range(self.population_size)]
        
        for generation in range(self.generations):
            # ì í•©ë„ í‰ê°€
            fitness_scores = [self.evaluate_fitness(ind) for ind in population]
            
            # ì„ íƒ (í† ë„ˆë¨¼íŠ¸ ì„ íƒ)
            new_population = []
            for _ in range(self.population_size // 2):
                parent1 = self.tournament_selection(population, fitness_scores)
                parent2 = self.tournament_selection(population, fitness_scores)
                
                # êµë°°
                if random.random() < self.crossover_rate:
                    child1, child2 = self.crossover(parent1, parent2)
                else:
                    child1, child2 = parent1.copy(), parent2.copy()
                
                # ëŒì—°ë³€ì´
                child1 = self.mutate(child1)
                child2 = self.mutate(child2)
                
                new_population.extend([child1, child2])
            
            population = new_population
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            best_fitness = max(fitness_scores)
            print(f"Generation {generation}: Best Fitness = {best_fitness:.4f}")
        
        # ìµœê³  ê°œì²´ ë°˜í™˜
        best_individual = population[fitness_scores.index(max(fitness_scores))]
        return best_individual
```

### 4. ë² ì´ì§€ì•ˆ ìµœì í™” (Bayesian Optimization)

#### ğŸ¯ ëª©ì 
**í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”** (ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° íŠœë‹)

#### ğŸ“Š ì ìš© ì˜ì—­
- Random Forest, XGBoost, LSTM ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- ì ì€ ì‹œë„ë¡œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°

#### ğŸ”§ êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ë²•

```python
# Optunaë¥¼ ì‚¬ìš©í•œ ë² ì´ì§€ì•ˆ ìµœì í™”
import optuna

class HyperparameterOptimizer:
    def __init__(self):
        self.study = optuna.create_study(direction='maximize')
    
    def objective_function(self, trial):
        """
        ëª©ì  í•¨ìˆ˜ ì •ì˜
        - trialì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
        - ëª¨ë¸ í›ˆë ¨ ë° ì„±ê³¼ í‰ê°€
        - ìµœëŒ€í™”í•  ì§€í‘œ ë°˜í™˜
        """
        # Random Forest í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
        rf_params = {
            'n_estimators': trial.suggest_int('rf_n_estimators', 50, 300),
            'max_depth': trial.suggest_int('rf_max_depth', 3, 20),
            'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)
        }
        
        # XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
        xgb_params = {
            'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 500),
            'max_depth': trial.suggest_int('xgb_max_depth', 3, 12),
            'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3),
            'subsample': trial.suggest_float('xgb_subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0)
        }
        
        # LSTM í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
        lstm_params = {
            'lstm_units': trial.suggest_int('lstm_units', 32, 128),
            'dense_units': trial.suggest_int('dense_units', 16, 64),
            'dropout': trial.suggest_float('dropout', 0.1, 0.5),
            'learning_rate': trial.suggest_float('lstm_learning_rate', 0.0001, 0.01)
        }
        
        # ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        performance = self.train_and_evaluate_models(rf_params, xgb_params, lstm_params)
        
        # ì¢…í•© ì„±ê³¼ ì ìˆ˜ ë°˜í™˜
        return performance['weighted_score']
    
    def train_and_evaluate_models(self, rf_params, xgb_params, lstm_params):
        """
        ì£¼ì–´ì§„ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        """
        # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í• 
        train_data, val_data = self.split_data()
        
        # Random Forest ëª¨ë¸ í›ˆë ¨
        rf_model = RandomForestClassifier(**rf_params)
        rf_model.fit(train_data['X'], train_data['y'])
        rf_score = rf_model.score(val_data['X'], val_data['y'])
        
        # XGBoost ëª¨ë¸ í›ˆë ¨
        xgb_model = XGBRegressor(**xgb_params)
        xgb_model.fit(train_data['X_reg'], train_data['y_reg'])
        xgb_score = self.calculate_r2_score(xgb_model, val_data['X_reg'], val_data['y_reg'])
        
        # LSTM ëª¨ë¸ í›ˆë ¨
        lstm_model = self.build_lstm_model(lstm_params)
        lstm_history = lstm_model.fit(train_data['X_seq'], train_data['y_seq'], 
                                     validation_data=(val_data['X_seq'], val_data['y_seq']),
                                     epochs=50, verbose=0)
        lstm_score = 1 - min(lstm_history.history['val_loss'])
        
        # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°
        weighted_score = rf_score * 0.4 + xgb_score * 0.4 + lstm_score * 0.2
        
        return {
            'rf_score': rf_score,
            'xgb_score': xgb_score,
            'lstm_score': lstm_score,
            'weighted_score': weighted_score
        }
    
    def optimize(self, n_trials=100):
        """ë² ì´ì§€ì•ˆ ìµœì í™” ì‹¤í–‰"""
        self.study.optimize(self.objective_function, n_trials=n_trials)
        
        # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°˜í™˜
        best_params = self.study.best_params
        best_score = self.study.best_value
        
        print(f"Best score: {best_score:.4f}")
        print(f"Best parameters: {best_params}")
        
        return best_params
```

## ğŸ”„ í†µí•© í•™ìŠµ í”„ë¡œì„¸ìŠ¤

### ì¼ì¼ í•™ìŠµ ì‚¬ì´í´

```python
class IntegratedLearningSystem:
    def __init__(self):
        self.ensemble_learner = EnsembleLearner()
        self.rl_agent = ParameterOptimizationAgent()
        self.performance_tracker = PerformanceTracker()
    
    def daily_learning_cycle(self):
        """
        ë§¤ì¼ ì‹¤í–‰ë˜ëŠ” í•™ìŠµ ì‚¬ì´í´
        """
        # 1. ì „ë‚  ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘
        yesterday_performance = self.performance_tracker.get_yesterday_performance()
        
        # 2. ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ì—…ë°ì´íŠ¸
        if yesterday_performance:
            state = self.rl_agent.get_state()
            action = self.rl_agent.last_action
            reward = self.rl_agent.calculate_reward(yesterday_performance)
            next_state = self.rl_agent.get_state()
            
            self.rl_agent.update_policy(state, action, reward, next_state)
        
        # 3. ì•™ìƒë¸” ëª¨ë¸ ì ì§„ì  í•™ìŠµ
        if len(self.performance_tracker.get_recent_data(days=7)) >= 7:
            recent_data = self.performance_tracker.get_recent_data(days=30)
            self.ensemble_learner.incremental_training(recent_data)
        
        # 4. ì˜¤ëŠ˜ì˜ íŒŒë¼ë¯¸í„° ì¡°ì •
        current_state = self.rl_agent.get_state()
        action = self.rl_agent.select_action(current_state)
        new_params = self.rl_agent.take_action(action)
        
        # 5. Phase 1, 2 ì‹œìŠ¤í…œì— ìƒˆ íŒŒë¼ë¯¸í„° ì ìš©
        self.update_phase_parameters(new_params)
        
        print(f"Daily learning completed. New parameters: {new_params}")

    def weekly_optimization(self):
        """
        ì£¼ë§ì— ì‹¤í–‰ë˜ëŠ” ëŒ€ê·œëª¨ ìµœì í™”
        """
        # 1. ìœ ì „ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ëŒ€í­ ì¡°ì •
        genetic_optimizer = GeneticParameterOptimizer()
        best_genetic_params = genetic_optimizer.optimize()
        
        # 2. ë² ì´ì§€ì•ˆ ìµœì í™”ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        hyperopt = HyperparameterOptimizer()
        best_hyperparams = hyperopt.optimize(n_trials=50)
        
        # 3. ì•™ìƒë¸” ëª¨ë¸ ì¬í›ˆë ¨
        self.ensemble_learner.full_retrain(best_hyperparams)
        
        # 4. ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ì— ìµœì  íŒŒë¼ë¯¸í„° ë°˜ì˜
        self.rl_agent.update_baseline(best_genetic_params)
        
        print(f"Weekly optimization completed.")
        print(f"Genetic algorithm best params: {best_genetic_params}")
        print(f"Best hyperparameters: {best_hyperparams}")
```

## ğŸ“Š ì„±ê³¼ ì¸¡ì • ë° í‰ê°€

### í‰ê°€ ì§€í‘œ

```python
class PerformanceMetrics:
    def calculate_comprehensive_score(self, results):
        """ì¢…í•© ì„±ê³¼ ì ìˆ˜ ê³„ì‚°"""
        metrics = {
            # ìˆ˜ìµì„± ì§€í‘œ
            'total_return': results['total_return'],
            'annualized_return': results['annualized_return'],
            'excess_return': results['return'] - results['benchmark_return'],
            
            # ìœ„í—˜ ì§€í‘œ
            'volatility': results['volatility'],
            'max_drawdown': results['max_drawdown'],
            'var_95': results['value_at_risk_95'],
            
            # ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥ 
            'sharpe_ratio': results['return'] / results['volatility'],
            'sortino_ratio': results['return'] / results['downside_deviation'],
            'calmar_ratio': results['annualized_return'] / results['max_drawdown'],
            
            # ì •í™•ë„ ì§€í‘œ
            'hit_ratio': results['winning_trades'] / results['total_trades'],
            'profit_factor': results['gross_profit'] / results['gross_loss'],
            'avg_win_loss_ratio': results['avg_win'] / results['avg_loss']
        }
        
        # ê°€ì¤‘ ì¢…í•© ì ìˆ˜
        score = (
            metrics['sharpe_ratio'] * 0.3 +
            metrics['hit_ratio'] * 0.2 +
            metrics['excess_return'] * 0.2 +
            (1 - metrics['max_drawdown']) * 0.2 +
            metrics['calmar_ratio'] * 0.1
        )
        
        return score, metrics
```

## ğŸ› ï¸ êµ¬í˜„ ë¡œë“œë§µ

### Phase 4.1: ê¸°ë³¸ ì„±ê³¼ ì¶”ì  (1-2ì£¼)
1. **PerformanceTracker êµ¬í˜„**
2. **ê¸°ë³¸ í†µê³„ ë¶„ì„ í•¨ìˆ˜**
3. **ë°ì´í„° ì €ì¥ êµ¬ì¡° ì„¤ê³„**

### Phase 4.2: ì•™ìƒë¸” í•™ìŠµ (2-3ì£¼)
1. **Random Forest ëª¨ë¸ êµ¬í˜„**
2. **XGBoost ëª¨ë¸ êµ¬í˜„**  
3. **LSTM ëª¨ë¸ êµ¬í˜„**
4. **ëª¨ë¸ ì•™ìƒë¸” ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ**

### Phase 4.3: ê°•í™”í•™ìŠµ (2-3ì£¼)
1. **PPO ì—ì´ì „íŠ¸ êµ¬í˜„**
2. **í™˜ê²½ ë° ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„**
3. **íŒŒë¼ë¯¸í„° ì¡°ì • ë©”ì»¤ë‹ˆì¦˜**
4. **ì¼ì¼ í•™ìŠµ ì‚¬ì´í´ êµ¬í˜„**

### Phase 4.4: ìµœì í™” ì‹œìŠ¤í…œ (2-3ì£¼)
1. **ìœ ì „ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„**
2. **ë² ì´ì§€ì•ˆ ìµœì í™” êµ¬í˜„**
3. **ë°±í…ŒìŠ¤íŠ¸ ìë™í™”**
4. **ì£¼ê°„ ìµœì í™” ì‚¬ì´í´**

### Phase 4.5: í†µí•© ë° ë°°í¬ (1-2ì£¼)
1. **ì „ì²´ ì‹œìŠ¤í…œ í†µí•©**
2. **ì„±ëŠ¥ ìµœì í™”**
3. **í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**
4. **ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**

## ğŸ“ ì°¸ê³  ìë£Œ

- **scikit-learn**: https://scikit-learn.org/
- **XGBoost**: https://xgboost.readthedocs.io/
- **TensorFlow**: https://tensorflow.org/
- **Optuna**: https://optuna.org/
- **ê°•í™”í•™ìŠµ PPO**: https://arxiv.org/abs/1707.06347
- **ìœ ì „ ì•Œê³ ë¦¬ì¦˜**: https://en.wikipedia.org/wiki/Genetic_algorithm
- **ë² ì´ì§€ì•ˆ ìµœì í™”**: https://distill.pub/2020/bayesian-optimization/

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025ë…„ 7ì›” 13ì¼  
**ì‘ì„±ì**: AI Assistant  
**ë²„ì „**: 1.0.0 