version: '3.8'

services:
  # 통합 스케줄러 (핵심 서비스)
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hantu-scheduler
    restart: unless-stopped
    command: ["python", "-m", "workflows.integrated_scheduler", "start"]
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./.env:/app/.env:ro
    environment:
      - TZ=Asia/Seoul
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ["CMD", "pgrep", "-f", "integrated_scheduler"]
      interval: 60s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # API 서버 (선택 - 외부 조회 필요시만)
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hantu-api
    restart: unless-stopped
    command: ["python", "api-server/main.py"]
    ports:
      - "127.0.0.1:8000:8000"  # 로컬만 노출 (Nginx 프록시 사용)
    volumes:
      - ./data:/app/data:ro
      - ./logs:/app/logs
      - ./.env:/app/.env:ro
    environment:
      - TZ=Asia/Seoul
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - scheduler
    profiles:
      - with-api  # docker-compose --profile with-api up

# 볼륨 정의
volumes:
  hantu-data:
  hantu-logs:

# 네트워크 정의
networks:
  default:
    name: hantu-network
